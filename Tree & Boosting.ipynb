{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import sklearn.datasets\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = pd.read_csv('music_data/train_X.csv')\n",
    "train_X = pd.read_csv('music_data/train_X_date_converted.csv')\n",
    "train_y = pd.read_csv('music_data/train_Y.csv')\n",
    "\n",
    "# val_X = pd.read_csv('music_data/valid_X.csv')\n",
    "val_X = pd.read_csv('music_data/valid_X_date_converted.csv')\n",
    "val_y = pd.read_csv('music_data/valid_Y.csv')\n",
    "\n",
    "# test_X = pd.read_csv('music_data/test_X.csv')\n",
    "test_X = pd.read_csv('music_data/test_X_date_converted.csv')\n",
    "test_y = pd.read_csv('music_data/test_Y.csv')\n",
    "\n",
    "# train_tiny_X = pd.read_csv('music_data/train_tiny_X.csv')\n",
    "train_tiny_X = pd.read_csv('music_data/train_tiny_X_date_converted.csv')\n",
    "train_tiny_y = pd.read_csv('music_data/train_tiny_Y.csv')\n",
    "\n",
    "# val_tiny_X = val_X[:1000].copy()\n",
    "val_tiny_X = pd.read_csv('music_data/val_tiny_X_date_converted.csv')\n",
    "val_tiny_y = val_y[:1000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'registration_init_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'registration_init_time'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2691a8339b4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Observing reasonable date for date time conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 2004 seems to be the earliest date. '1970-01-01' is essentially null value (1 in train).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'registration_init_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'expiration_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'registration_init_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'expiration_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'registration_init_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'expiration_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'registration_init_time'"
     ]
    }
   ],
   "source": [
    "# Observing reasonable date for date time conversion\n",
    "# 2004 seems to be the earliest date. '1970-01-01' is essentially null value (1 in train).\n",
    "print('train x', train_X['registration_init_time'].min(), train_X['expiration_date'].min())\n",
    "print('val x', val_X['registration_init_time'].min(), val_X['expiration_date'].min())\n",
    "print('test x', test_X['registration_init_time'].min(), test_X['expiration_date'].min())\n",
    "\n",
    "\n",
    "# Not many records smaller than '2000-01-01'. Reasonable to not treat them specially\n",
    "print(train_X['expiration_date'].apply(lambda date: date == '1970-01-01').sum(), '1970-01-01 in train set')\n",
    "print(val_X['expiration_date'].apply(lambda date: date == '1970-01-01').sum(), '1970-01-01 in val set')\n",
    "\n",
    "print(train_X['expiration_date'].apply(lambda date: date < '2000-01-01').sum(), 'smaller than 2000-01-01 in train set')\n",
    "print(val_X['expiration_date'].apply(lambda date: date < '2000-01-01').sum(), 'smaller than 2000-01-01 in val set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_int(column, base_date=datetime.strptime('2000-01-01', \"%Y-%m-%d\")):\n",
    "    \"\"\"\n",
    "    Convert date to day counts since base_date for given columns.\n",
    "    \n",
    "    :param column: pandas column containing date representations as str value\n",
    "    :param base_date: base date from which date is counted. i.e. 2000-01-02 will be day '1' comparing to '2000-01-01'\n",
    "    \"\"\"\n",
    "    \n",
    "    def date_diff(date):\n",
    "        date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "        return (date - base_date).days\n",
    "    \n",
    "    return column.apply(date_diff)\n",
    "\n",
    "def convert_date_columns_to_int(dataframes, cols=['registration_init_time', 'expiration_date'], saving=True):\n",
    "    count = 0\n",
    "    total = len(dataframes)\n",
    "    for df_name, df in dataframes.items():\n",
    "        count += 1\n",
    "        print(\"Starting {} ...\".format(df_name))\n",
    "        for col in cols:\n",
    "            df[col+'_int'] = date_to_int(df[col])\n",
    "        df = df.drop(columns=cols)\n",
    "        dataframes[df_name] = df\n",
    "        \n",
    "        if saving:\n",
    "            print(\"Saving {} ...\".format(df_name))\n",
    "            df.to_csv('music_data/'+ df_name + '_date_converted.csv')\n",
    "        \n",
    "        print(\"====== Done {} / {} ======\".format(count, total))\n",
    "    return dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all data\n",
    "converted_dfs = convert_date_columns_to_int({\n",
    "    'train_X': train_X,\n",
    "    'valid_X': val_X,\n",
    "    'test_X': test_X,\n",
    "    'train_tiny_X': train_tiny_X,\n",
    "    'val_tiny_X': val_tiny_X,\n",
    "})\n",
    "train_X = converted_dfs['train_X']\n",
    "val_X = converted_dfs['valid_X']\n",
    "test_X = converted_dfs['test_X']\n",
    "train_tiny_X = converted_dfs['train_tiny_X']\n",
    "val_tiny_X = converted_dfs['val_tiny_X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgbc(train_X, train_y, val_X, val_y):\n",
    "    params = {\n",
    "        \"objective\" : \"binary\",\n",
    "        \"metric\" : \"binary_logloss\", \n",
    "        \"num_leaves\" : 30,\n",
    "        \"min_child_samples\" : 100,\n",
    "        \"learning_rate\" : 0.1,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.5,\n",
    "        \"bagging_frequency\" : 5,\n",
    "        \"bagging_seed\" : 2018,\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=100)\n",
    "\n",
    "    pred_val_y = model.predict(val_X, num_iteration=model.best_iteration)\n",
    "    return model, pred_val_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on tiny dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.651618\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's binary_logloss: 0.639451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.69      0.63       477\n",
      "         1.0       0.66      0.55      0.60       523\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      1000\n",
      "   macro avg       0.62      0.62      0.62      1000\n",
      "weighted avg       0.62      0.62      0.61      1000\n",
      "\n",
      "0.6819830761892165\n"
     ]
    }
   ],
   "source": [
    "modelC, pred_val_y = run_lgbc(train_tiny_X, train_tiny_y['target'], val_tiny_X, val_tiny_y['target'])\n",
    "print(classification_report(val_tiny_y['target'], modelC.predict(val_tiny_X)>0.5))\n",
    "print(roc_auc_score(val_tiny_y['target'], modelC.predict(val_tiny_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.6224\n",
      "[200]\tvalid_0's binary_logloss: 0.616636\n",
      "[300]\tvalid_0's binary_logloss: 0.612586\n",
      "[400]\tvalid_0's binary_logloss: 0.609499\n",
      "[500]\tvalid_0's binary_logloss: 0.606984\n",
      "[600]\tvalid_0's binary_logloss: 0.604466\n",
      "[700]\tvalid_0's binary_logloss: 0.602129\n",
      "[800]\tvalid_0's binary_logloss: 0.60016\n",
      "[900]\tvalid_0's binary_logloss: 0.598241\n",
      "[1000]\tvalid_0's binary_logloss: 0.596447\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.596447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.70      0.68    732500\n",
      "         1.0       0.69      0.66      0.67    742961\n",
      "\n",
      "   micro avg       0.68      0.68      0.68   1475461\n",
      "   macro avg       0.68      0.68      0.68   1475461\n",
      "weighted avg       0.68      0.68      0.68   1475461\n",
      "\n",
      "0.7449332780580912\n"
     ]
    }
   ],
   "source": [
    "modelC, pred_val_y = run_lgbc(train_X, train_y['target'], val_X, val_y['target'])\n",
    "print(classification_report(val_y['target'], modelC.predict(val_X)>0.5))\n",
    "print(roc_auc_score(val_y['target'], modelC.predict(val_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgb(X_train, y_train, X_val, y_val):\n",
    "    params = {'objective': 'binary:logistic',\n",
    "              #'eval_metric':\"binary_logloss\",\n",
    "              'eta': 0.001,\n",
    "              'max_depth': 10,\n",
    "              'subsample': 0.6,\n",
    "              'colsample_bytree': 0.6,\n",
    "              'alpha':0.001,\n",
    "              'random_state': 42,\n",
    "              'silent': True}\n",
    "\n",
    "    xgb_train_data = xgb.DMatrix(X_train.values, y_train.values)\n",
    "    xgb_val_data = xgb.DMatrix(X_val.values, y_val.values)\n",
    "    #xgb_test_data = xgb.DMatrix(X_test.values, y_test.values)\n",
    "    #xgb_submit_data = xgb.DMatrix(X_test)\n",
    "    model = xgb.train(params, xgb_train_data, \n",
    "                      num_boost_round=2000, \n",
    "                      evals= [(xgb_train_data, 'train'), (xgb_val_data, 'valid')],\n",
    "                      early_stopping_rounds=100, \n",
    "                      verbose_eval=100\n",
    "                     )\n",
    "\n",
    "    y_pred_train = model.predict(xgb_train_data, ntree_limit=model.best_ntree_limit)\n",
    "    y_pred_val = model.predict(xgb_val_data, ntree_limit=model.best_ntree_limit)\n",
    "    #y_pred_test = model.predict(xgb_test_data, ntree_limit=model.best_ntree_limit)\n",
    "    #y_pred_submit = model.predict(xgb_submit_data, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "    return model, y_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.3236\tvalid-error:0.436\n",
      "Multiple eval metrics have been passed: 'valid-error' will be used for early stopping.\n",
      "\n",
      "Will train until valid-error hasn't improved in 100 rounds.\n",
      "[100]\ttrain-error:0.2271\tvalid-error:0.365\n",
      "[200]\ttrain-error:0.222\tvalid-error:0.37\n",
      "Stopping. Best iteration:\n",
      "[111]\ttrain-error:0.2241\tvalid-error:0.361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tiny data debugging\n",
    "#starttime = time.time()\n",
    "xgb_model, xgb_preds_val = run_xgb(train_tiny_X,train_tiny_y['target'], val_tiny_X, val_tiny_y['target'])\n",
    "#print('time: {}'.format(time.time()-starttime))\n",
    "#print(np.sqrt(metrics.mean_squared_error(val_tiny_y['target'], xgb_preds_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5094437  0.5116189  0.52351433 0.5169619  0.496747   0.4858081\n",
      " 0.51528674 0.49535495 0.4902183  0.4839496  0.49124894 0.48721212\n",
      " 0.50027484 0.48574078 0.49802402 0.5197338  0.50149816 0.50985366\n",
      " 0.5167198  0.49214998 0.47583276 0.51541704 0.4755286  0.4870112\n",
      " 0.5128517  0.504228   0.48142874 0.48501182 0.4917307  0.47692364\n",
      " 0.50448704 0.5264882  0.49648333 0.49634477 0.48507923 0.51000655\n",
      " 0.5175798  0.5230582  0.485356   0.48269445 0.46685663 0.4792754\n",
      " 0.48985386 0.4853551  0.5014464  0.52741075 0.5012205  0.52709043\n",
      " 0.49615115 0.4947971  0.51321733 0.49641198 0.49220946 0.4883308\n",
      " 0.49451777 0.4898305  0.5014147  0.4938358  0.49146858 0.503562\n",
      " 0.50240135 0.5140569  0.48526976 0.48805332 0.48640925 0.4783012\n",
      " 0.5151044  0.4965558  0.50376976 0.48863897 0.48425198 0.50740486\n",
      " 0.52644414 0.49462146 0.47789416 0.5221683  0.50242686 0.4924471\n",
      " 0.527111   0.5092239  0.48563576 0.48314306 0.50607425 0.46546334\n",
      " 0.5275891  0.5014371  0.49257156 0.5185346  0.4915444  0.49103764\n",
      " 0.51705813 0.5012258  0.52751017 0.5059949  0.48516613 0.4804107\n",
      " 0.48998913 0.5079797  0.48484388 0.5005069 ]\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    1.0\n",
      "6    1.0\n",
      "7    1.0\n",
      "8    0.0\n",
      "9    1.0\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(xgb_preds_val[:100])\n",
    "print(val_tiny_y['target'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.360643\tvalid-error:0.362191\n",
      "Multiple eval metrics have been passed: 'valid-error' will be used for early stopping.\n",
      "\n",
      "Will train until valid-error hasn't improved in 100 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b9b381f6dad5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#full data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_preds_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-2ad3f3b65b5a>\u001b[0m in \u001b[0;36mrun_xgb\u001b[0;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m     18\u001b[0m                       \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxgb_val_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                       \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                       \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                      )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1110\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#full data\n",
    "xgb_model, xgb_preds_val = run_xgb(train_X,train_y['target'], val_X, val_y['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "pipelines = {\n",
    "    \"dtclass\": make_pipeline(DecisionTreeClassifier(random_state=0))\n",
    "}\n",
    "decisiontree_hyperparameters = {\n",
    "    'decisiontreeclassifier__max_depth' : np.arange(3, 10),\n",
    "    'decisiontreeclassifier__max_features' : np.arange(3, 8),\n",
    "    'decisiontreeclassifier__min_samples_split' : np.arange(2, 15),\n",
    "    \"decisiontreeclassifier__min_samples_leaf\" : np.arange(1,3)\n",
    "}\n",
    "dtclass_model = RandomizedSearchCV(pipelines['dtclass'],decisiontree_hyperparameters,n_iter = 100,cv=3, scoring = 'roc_auc')\n",
    "dtclass_model.fit(train_tiny_X, train_tiny_y['target'])\n",
    "print(dtclass_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
