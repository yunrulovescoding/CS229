{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic and SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import sklearn.datasets\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv('new_data/new_train_X.csv')\n",
    "val_X = pd.read_csv('new_data/new_valid_X.csv')\n",
    "train_y = pd.read_csv('new_data/new_train_y.csv')\n",
    "val_y = pd.read_csv('new_data/new_valid_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>msno</th>\n",
       "      <th>song_id</th>\n",
       "      <th>source_screen_name</th>\n",
       "      <th>source_system_tab</th>\n",
       "      <th>source_type</th>\n",
       "      <th>song_length</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>composer</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>language</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>time</th>\n",
       "      <th>registration_init_time_int</th>\n",
       "      <th>expiration_date_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4014890</td>\n",
       "      <td>7039846</td>\n",
       "      <td>785</td>\n",
       "      <td>141648</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>219454.0</td>\n",
       "      <td>371</td>\n",
       "      <td>44988</td>\n",
       "      <td>20734</td>\n",
       "      <td>4032</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.708647</td>\n",
       "      <td>4155</td>\n",
       "      <td>6465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>865446</td>\n",
       "      <td>2067552</td>\n",
       "      <td>9176</td>\n",
       "      <td>156565</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>270001.0</td>\n",
       "      <td>127</td>\n",
       "      <td>8947</td>\n",
       "      <td>74276</td>\n",
       "      <td>26024</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.208124</td>\n",
       "      <td>4384</td>\n",
       "      <td>6487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1151370</td>\n",
       "      <td>5503771</td>\n",
       "      <td>31040</td>\n",
       "      <td>43786</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>265822.0</td>\n",
       "      <td>371</td>\n",
       "      <td>40039</td>\n",
       "      <td>84290</td>\n",
       "      <td>35947</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.554022</td>\n",
       "      <td>2890</td>\n",
       "      <td>6479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>575108</td>\n",
       "      <td>639057</td>\n",
       "      <td>26412</td>\n",
       "      <td>387047</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>266031.0</td>\n",
       "      <td>364</td>\n",
       "      <td>42827</td>\n",
       "      <td>71260</td>\n",
       "      <td>26024</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.064329</td>\n",
       "      <td>6153</td>\n",
       "      <td>6486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>460130</td>\n",
       "      <td>6368926</td>\n",
       "      <td>24075</td>\n",
       "      <td>136842</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>280346.0</td>\n",
       "      <td>364</td>\n",
       "      <td>43072</td>\n",
       "      <td>81070</td>\n",
       "      <td>31877</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.641111</td>\n",
       "      <td>5634</td>\n",
       "      <td>6874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1   msno  song_id  source_screen_name  \\\n",
       "0     4014890       7039846    785   141648                  18   \n",
       "1      865446       2067552   9176   156565                  16   \n",
       "2     1151370       5503771  31040    43786                  11   \n",
       "3      575108        639057  26412   387047                   8   \n",
       "4      460130       6368926  24075   136842                   4   \n",
       "\n",
       "   source_system_tab  source_type  song_length  genre_ids  artist_name  \\\n",
       "0                  7            7     219454.0        371        44988   \n",
       "1                  6            8     270001.0        127         8947   \n",
       "2                  0            7     265822.0        371        40039   \n",
       "3                  3            4     266031.0        364        42827   \n",
       "4                  0            7     280346.0        364        43072   \n",
       "\n",
       "   composer  lyricist  language  city  bd  gender  registered_via      time  \\\n",
       "0     20734      4032         2     0   0       2               2  0.708647   \n",
       "1     74276     26024         9     0   0       2               2  0.208124   \n",
       "2     84290     35947         2    12  33       1               3  0.554022   \n",
       "3     71260     26024         2     0   0       2               2  0.064329   \n",
       "4     81070     31877         2     0   0       2               3  0.641111   \n",
       "\n",
       "   registration_init_time_int  expiration_date_int  \n",
       "0                        4155                 6465  \n",
       "1                        4384                 6487  \n",
       "2                        2890                 6479  \n",
       "3                        6153                 6486  \n",
       "4                        5634                 6874  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0     0.0\n",
       "1     1.0\n",
       "2     0.0\n",
       "3     1.0\n",
       "4     1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(552909, 20) (552909, 1)\n",
      "(92152, 20) (92152, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape,train_y.shape)\n",
    "print(val_X.shape,val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "catCols = ['msno', 'song_id', 'source_screen_name', 'source_system_tab', 'source_type', 'genre_ids', 'artist_name', \n",
    "           'composer', 'lyricist', 'language', 'city', 'gender', 'registered_via']\n",
    "numCols = ['bd', 'song_length','Unnamed: 0','Unnamed: 0.1','time','registration_init_time_int','expiration_date_int']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.93      4985\n",
      "         1.0       0.93      0.94      0.93      5015\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "0.9814643531791786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "#debugging with tiny data set\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
    "                                               ('cat', categorical_transformer, catCols)])\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression())])\n",
    "\n",
    "clf.fit(train_tiny_X, train_tiny_y['target'])\n",
    "print(\"Model score on training set:\")\n",
    "print(\"model score: %.3f\" % clf.score(train_tiny_X, train_tiny_y['target']))\n",
    "print(classification_report(train_tiny_y['target'], clf.predict(train_tiny_X)))\n",
    "print(roc_auc_score(train_tiny_y['target'], clf.predict_proba(train_tiny_X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.62      0.62       477\n",
      "         1.0       0.65      0.65      0.65       523\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      1000\n",
      "   macro avg       0.63      0.63      0.63      1000\n",
      "weighted avg       0.63      0.63      0.63      1000\n",
      "\n",
      "0.6737737051601188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "print(\"Model score on validation set:\")\n",
    "print(\"model score: %.3f\" % clf.score(val_tiny_X, val_tiny_y['target']))\n",
    "print(classification_report(val_tiny_y['target'], clf.predict(val_tiny_X)))\n",
    "print(roc_auc_score(val_tiny_y['target'], clf.predict_proba(val_tiny_X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN IT YET!!!!!! HUGE DATASET!!!\n",
    "\n",
    "# numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "# categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "# preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
    "#                                                ('cat', categorical_transformer, catCols)])\n",
    "# clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                       ('classifier', LogisticRegression())])\n",
    "\n",
    "# clf.fit(train_X, train_y['target'])\n",
    "# print(\"model score: %.3f\" % clf.score(val_X, val_y['target']))\n",
    "# print(classification_report(val_y['target'], clf.predict(val_X)))\n",
    "# print(roc_auc_score(val_y, clf.predict_proba(val_X)['target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default: Logistic Regression with No Penalty, learning rate = 'optimal'  \n",
    "val acc = 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 2.36, NNZs: 172997, Bias: -0.003480, T: 497618, Avg. loss: 0.574006\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.58, NNZs: 172997, Bias: -0.004140, T: 995236, Avg. loss: 0.568198\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.65, NNZs: 172997, Bias: -0.004343, T: 1492854, Avg. loss: 0.565144\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5.62, NNZs: 172997, Bias: -0.004314, T: 1990472, Avg. loss: 0.562776\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6.55, NNZs: 172997, Bias: -0.004610, T: 2488090, Avg. loss: 0.560732\n",
      "Total training time: 2.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.42, NNZs: 172997, Bias: -0.004966, T: 2985708, Avg. loss: 0.558962\n",
      "Total training time: 2.50 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 7.59, NNZs: 172997, Bias: -0.004683, T: 3483326, Avg. loss: 0.557016\n",
      "Total training time: 2.94 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 7.76, NNZs: 172997, Bias: -0.004715, T: 3980944, Avg. loss: 0.556677\n",
      "Total training time: 3.37 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 7.92, NNZs: 172997, Bias: -0.004792, T: 4478562, Avg. loss: 0.556397\n",
      "Total training time: 3.81 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 8.09, NNZs: 172997, Bias: -0.004873, T: 4976180, Avg. loss: 0.556063\n",
      "Total training time: 4.26 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 8.26, NNZs: 172997, Bias: -0.004854, T: 5473798, Avg. loss: 0.555770\n",
      "Total training time: 4.70 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 8.29, NNZs: 172997, Bias: -0.004824, T: 5971416, Avg. loss: 0.555397\n",
      "Total training time: 5.15 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 8.32, NNZs: 172997, Bias: -0.004876, T: 6469034, Avg. loss: 0.555333\n",
      "Total training time: 5.59 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.35, NNZs: 172997, Bias: -0.004890, T: 6966652, Avg. loss: 0.555278\n",
      "Total training time: 6.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 8.39, NNZs: 172997, Bias: -0.004844, T: 7464270, Avg. loss: 0.555220\n",
      "Total training time: 6.48 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 8.42, NNZs: 172997, Bias: -0.004905, T: 7961888, Avg. loss: 0.555159\n",
      "Total training time: 6.94 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 8.43, NNZs: 172997, Bias: -0.004873, T: 8459506, Avg. loss: 0.555084\n",
      "Total training time: 7.41 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 8.43, NNZs: 172997, Bias: -0.004876, T: 8957124, Avg. loss: 0.555067\n",
      "Total training time: 7.87 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 8.44, NNZs: 172997, Bias: -0.004873, T: 9454742, Avg. loss: 0.555055\n",
      "Total training time: 8.33 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 8.45, NNZs: 172997, Bias: -0.004865, T: 9952360, Avg. loss: 0.555042\n",
      "Total training time: 8.78 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 8.45, NNZs: 172997, Bias: -0.004863, T: 10449978, Avg. loss: 0.555032\n",
      "Total training time: 9.24 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 8.45, NNZs: 172997, Bias: -0.004868, T: 10947596, Avg. loss: 0.555014\n",
      "Total training time: 9.71 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 8.45, NNZs: 172997, Bias: -0.004871, T: 11445214, Avg. loss: 0.555011\n",
      "Total training time: 10.17 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 8.46, NNZs: 172997, Bias: -0.004872, T: 11942832, Avg. loss: 0.555009\n",
      "Total training time: 10.62 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 8.46, NNZs: 172997, Bias: -0.004873, T: 12440450, Avg. loss: 0.555006\n",
      "Total training time: 11.07 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 8.46, NNZs: 172997, Bias: -0.004873, T: 12938068, Avg. loss: 0.555004\n",
      "Total training time: 11.52 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 8.46, NNZs: 172997, Bias: -0.004874, T: 13435686, Avg. loss: 0.555000\n",
      "Total training time: 11.97 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 8.46, NNZs: 172997, Bias: -0.004874, T: 13933304, Avg. loss: 0.555000\n",
      "Total training time: 12.42 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 8.46, NNZs: 172997, Bias: -0.004874, T: 14430922, Avg. loss: 0.554999\n",
      "Total training time: 12.86 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 8.46, NNZs: 172997, Bias: -0.004874, T: 14928540, Avg. loss: 0.554999\n",
      "Total training time: 13.31 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 8.46, NNZs: 172997, Bias: -0.004874, T: 15426158, Avg. loss: 0.554998\n",
      "Total training time: 13.76 seconds.\n",
      "Convergence after 31 epochs took 13.86 seconds\n",
      "model score: 0.656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.63      0.65     45690\n",
      "         1.0       0.65      0.68      0.67     46462\n",
      "\n",
      "    accuracy                           0.66     92152\n",
      "   macro avg       0.66      0.66      0.66     92152\n",
      "weighted avg       0.66      0.66      0.66     92152\n",
      "\n",
      "0.7137153810833383\n"
     ]
    }
   ],
   "source": [
    "#mini batch training with full data and early stopping\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
    "                                               ('cat', categorical_transformer, catCols)])\n",
    "clf_log = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                ('classifier', SGDClassifier(loss='log', penalty=None, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, \n",
    "                                max_iter=1000, tol=0.001, shuffle=True, verbose=1, epsilon=0.1, n_jobs=None, \n",
    "                                random_state=None, learning_rate='adaptive', eta0=0.001, \n",
    "                                power_t=0.5, early_stopping=True, validation_fraction=0.1, n_iter_no_change=5, \n",
    "                                class_weight=None, warm_start=True, average=False))])\n",
    "#default, no penalty\n",
    "clf_log.fit(train_X, train_y['target'])\n",
    "print(\"model score: %.3f\" % clf_log.score(val_X, val_y['target']))\n",
    "print(classification_report(val_y['target'], clf_log.predict(val_X)))\n",
    "print(roc_auc_score(val_y['target'], clf_log.predict_proba(val_X)[:,1]))\n",
    "#val acc 0.660\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.68      0.66     45690\n",
      "         1.0       0.67      0.63      0.65     46462\n",
      "\n",
      "    accuracy                           0.66     92152\n",
      "   macro avg       0.66      0.66      0.66     92152\n",
      "weighted avg       0.66      0.66      0.66     92152\n",
      "\n",
      "0.6555275025289365\n"
     ]
    }
   ],
   "source": [
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
    "                                               ('cat', categorical_transformer, catCols)])\n",
    "clf_svm = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                ('classifier', SGDClassifier(loss='hinge', penalty=None, early_stopping=True, \n",
    "                                             validation_fraction=0.1, n_iter_no_change=5))])\n",
    "#default, no penalty\n",
    "clf_svm.fit(train_X, train_y['target'])\n",
    "print(\"model score: %.3f\" % clf_svm.score(val_X, val_y['target']))\n",
    "print(classification_report(val_y['target'], clf_svm.predict(val_X)))\n",
    "print(roc_auc_score(val_y['target'], clf_svm.predict(val_X)>0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best SVM model(with no penalty):  \n",
    "learning rate = 'adaptive', eta = 0.01  \n",
    "best val acc = 0.697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta0: 0.01\n",
      "best val acc: 0.6872449865439708\n"
     ]
    }
   ],
   "source": [
    "etas = [0.01]\n",
    "best_model_svm = None\n",
    "best_model_score_svm = 0.0\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
    "                                               ('cat', categorical_transformer, catCols)])\n",
    "for eta in etas:\n",
    "    clf_svm = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                    ('classifier', SGDClassifier(loss='hinge', penalty=None, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, \n",
    "                                    max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, \n",
    "                                    random_state=None, learning_rate='adaptive', eta0=eta, \n",
    "                                    power_t=0.5, early_stopping=True, validation_fraction=0.1, n_iter_no_change=5, \n",
    "                                    class_weight=None, warm_start=True, average=False))])\n",
    "    clf_svm.fit(train_X, train_y['target'])\n",
    "    model_score = clf_svm.score(val_X, val_y['target'])\n",
    "    if model_score > best_model_score_svm:\n",
    "        best_model_score_svm = model_score\n",
    "        best_model_svm = clf_svm\n",
    "        print('eta0:',eta)\n",
    "        print('best val acc:',best_model_score_svm)\n",
    "                                        \n",
    "# print(\"best model score:\" ,best_model_score_svm)\n",
    "# print(classification_report(val_y['target'], best_model_svm.predict(val_X)))\n",
    "# print(roc_auc_score(val_y['target'], best_model_svm.predict(val_X)>0.5))\n",
    "#print(roc_auc_score(val_y['target'], clf_svm.predict_proba(val_X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model score: 0.6872449865439708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.68      0.68     45690\n",
      "         1.0       0.69      0.69      0.69     46462\n",
      "\n",
      "    accuracy                           0.69     92152\n",
      "   macro avg       0.69      0.69      0.69     92152\n",
      "weighted avg       0.69      0.69      0.69     92152\n",
      "\n",
      "0.6872018519378474\n"
     ]
    }
   ],
   "source": [
    "print(\"best model score:\" ,best_model_score_svm)\n",
    "print(classification_report(val_y['target'], best_model_svm.predict(val_X)))\n",
    "print(roc_auc_score(val_y['target'], best_model_svm.predict(val_X)>0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best logistic regression model(with no penalty):  \n",
    "learning rate = 'adaptive', eta = 0.01  \n",
    "best val acc = 0.694"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: optimal eta0: 0.01\n",
      "best val acc: 0.6600669214570903\n",
      "learning_rate: optimal eta0: 0.0001\n",
      "best val acc: 0.6603908880004283\n",
      "learning_rate: adaptive eta0: 0.01\n",
      "best val acc: 0.694752351976772\n",
      "best model score: 0.694752351976772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.69      0.69    732500\n",
      "         1.0       0.70      0.70      0.70    742961\n",
      "\n",
      "   micro avg       0.69      0.69      0.69   1475461\n",
      "   macro avg       0.69      0.69      0.69   1475461\n",
      "weighted avg       0.69      0.69      0.69   1475461\n",
      "\n",
      "0.763170012584044\n"
     ]
    }
   ],
   "source": [
    "#fine tune learning rate on logistic regression\n",
    "best_model_df = None\n",
    "best_model_score_df = 0.0\n",
    "learning_rate = ['optimal','invscaling','adaptive']\n",
    "etas = [0.01,0.001,0.0001]\n",
    "for lr in learning_rate:\n",
    "    for eta in etas:\n",
    "        clf_log_df = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', SGDClassifier(loss='log', penalty=None, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, \n",
    "                                        max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, \n",
    "                                        random_state=None, learning_rate=lr, eta0=eta, \n",
    "                                        power_t=0.5, early_stopping=True, validation_fraction=0.1, n_iter_no_change=5, \n",
    "                                        class_weight=None, warm_start=True, average=False))])\n",
    "        clf_log_df.fit(train_X, train_y['target'])\n",
    "        model_score = clf_log_df.score(val_X, val_y['target'])\n",
    "        if model_score > best_model_score_df:\n",
    "            best_model_score_df = model_score\n",
    "            best_model_df = clf_log_df\n",
    "            print('learning_rate:',lr,'eta0:',eta)\n",
    "            print('best val acc:',best_model_score_df)\n",
    "                                        \n",
    "print(\"best model score:\" ,best_model_score_df)\n",
    "print(classification_report(val_y['target'], best_model_df.predict(val_X)))\n",
    "print(roc_auc_score(val_y['target'], best_model_df.predict_proba(val_X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: log penalty: l1 val acc: 0.6449670110252627\n",
      "best loss: log best penalty: l1 best val acc: 0.6449670110252627\n",
      "loss: log penalty: l2 val acc: 0.6635016060421912\n",
      "best loss: log best penalty: l2 best val acc: 0.6635016060421912\n",
      "loss: log penalty: elasticnet val acc: 0.6547443354457853\n",
      "loss: hinge penalty: l1 val acc: 0.6381087768035419\n",
      "loss: hinge penalty: l2 val acc: 0.6457049223022832\n",
      "loss: hinge penalty: elasticnet val acc: 0.641071273548051\n",
      "best model score: 0.6635016060421912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.64      0.65     45690\n",
      "         1.0       0.66      0.68      0.67     46462\n",
      "\n",
      "    accuracy                           0.66     92152\n",
      "   macro avg       0.66      0.66      0.66     92152\n",
      "weighted avg       0.66      0.66      0.66     92152\n",
      "\n",
      "0.7247404866963721\n"
     ]
    }
   ],
   "source": [
    "#fine tune SVM and Logistic regression with penalty\n",
    "best_model = None\n",
    "best_model_score = 0.0\n",
    "loss = ['log', 'hinge']\n",
    "penalty = ['l1','l2','elasticnet']\n",
    "\n",
    "for ls in loss:\n",
    "    for plty in penalty: \n",
    "        clf_log_tune = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', SGDClassifier(loss=ls, penalty=plty, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, \n",
    "                                        max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, \n",
    "                                        random_state=None, learning_rate='adaptive', eta0=0.01, \n",
    "                                        power_t=0.5, early_stopping=True, validation_fraction=0.1, n_iter_no_change=5, \n",
    "                                        class_weight=None, warm_start=True, average=False))])\n",
    "        clf_log_tune.fit(train_X, train_y['target'])\n",
    "        model_score = clf_log_tune.score(val_X, val_y['target'])\n",
    "        print( 'loss:', ls, 'penalty:', plty,'val acc:', model_score)\n",
    "        if model_score > best_model_score:\n",
    "            best_model_score = model_score\n",
    "            best_model = clf_log_tune\n",
    "            print( 'best loss:', ls, 'best penalty:', plty,'best val acc:', model_score)\n",
    "\n",
    "print(\"best model score:\" ,best_model_score)\n",
    "print(classification_report(val_y['target'], best_model.predict(val_X)))\n",
    "print(roc_auc_score(val_y['target'], best_model.predict_proba(val_X)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8945710cedbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#rbf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_approximation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRBFSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnumeric_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scaler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcategorical_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'onehot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "#rbf\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
    "                                               ('cat', categorical_transformer, catCols)])\n",
    "rbf_feature = RBFSampler(gamma=0.2, random_state=1)\n",
    "clf_kernel = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                ('kernel',rbf_feature),\n",
    "                ('classifier', SGDClassifier(loss='hinge', penalty=None, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, \n",
    "                                max_iter=1000, tol=0.001, shuffle=True, verbose=1, epsilon=0.1, n_jobs=None, \n",
    "                                random_state=None, learning_rate='adaptive', eta0=0.01, \n",
    "                                power_t=0.5, early_stopping=True, validation_fraction=0.1, n_iter_no_change=5))])\n",
    "#default, no penalty\n",
    "clf_kernel.fit(train_tiny_X, train_tiny_y['target'])\n",
    "print(\"model score: %.3f\" % clf_kernel.score(val_tiny_X, val_tiny_y['target']))\n",
    "print(classification_report(val_tiny_y['target'], clf_kernel.predict(val_tiny_X)))\n",
    "#print(roc_auc_score(val_tiny_y['target'], clf_kernel.predict_proba(val_tiny_X)[:,1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.660\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.69      0.71      4985\n",
      "         1.0       0.71      0.73      0.72      5015\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.71      0.71      0.71     10000\n",
      "weighted avg       0.71      0.71      0.71     10000\n",
      "\n",
      "0.7882900546104915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
    "                                               ('cat', categorical_transformer, catCols)])\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(penalty='l1'))])\n",
    "\n",
    "clf.fit(train_tiny_X, train_tiny_y['target'])\n",
    "print(\"model score: %.3f\" % clf.score(val_tiny_X, val_tiny_y['target']))\n",
    "print(classification_report(train_tiny_y['target'], clf.predict(train_tiny_X)))\n",
    "print(roc_auc_score(train_tiny_y['target'], clf.predict_proba(train_tiny_X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.660\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.65      0.65       477\n",
      "         1.0       0.68      0.67      0.67       523\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      1000\n",
      "   macro avg       0.66      0.66      0.66      1000\n",
      "weighted avg       0.66      0.66      0.66      1000\n",
      "\n",
      "0.6840073595728562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "print(\"model score: %.3f\" % clf.score(val_tiny_X, val_tiny_y['target']))\n",
    "print(classification_report(val_tiny_y['target'], clf.predict(val_tiny_X)))\n",
    "print(roc_auc_score(val_tiny_y['target'], clf.predict_proba(val_tiny_X)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.93      4985\n",
      "         1.0       0.93      0.94      0.93      5015\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "0.9814643531791786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(penalty='l2'))])\n",
    "\n",
    "clf.fit(train_tiny_X, train_tiny_y['target'])\n",
    "print(\"model score: %.3f\" % clf.score(val_tiny_X, val_tiny_y['target']))\n",
    "print(classification_report(train_tiny_y['target'], clf.predict(train_tiny_X)))\n",
    "print(roc_auc_score(train_tiny_y['target'], clf.predict_proba(train_tiny_X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.62      0.62       477\n",
      "         1.0       0.65      0.65      0.65       523\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      1000\n",
      "   macro avg       0.63      0.63      0.63      1000\n",
      "weighted avg       0.63      0.63      0.63      1000\n",
      "\n",
      "0.6737737051601188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "print(\"model score: %.3f\" % clf.score(val_tiny_X, val_tiny_y['target']))\n",
    "print(classification_report(val_tiny_y['target'], clf.predict(val_tiny_X)))\n",
    "print(roc_auc_score(val_tiny_y['target'], clf.predict_proba(val_tiny_X)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting & Decision Tree\n",
    "Moved to \"Tree & Boosting\" Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48453905786700674\n",
      "alpha: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49497671219414635\n",
      "alpha: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49993324554384255\n",
      "alpha: 0.2\n",
      "0.49993324554384255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "alphas = [0.01,0.05,0.1,0.2]\n",
    "for a in alphas:\n",
    "    print('alpha: {}'.format(a))\n",
    "    lasso = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor',  Lasso(alpha = a))])\n",
    "    lasso.fit(train_tiny_X, train_tiny_y['target'])\n",
    "    print(np.sqrt(metrics.mean_squared_error(val_tiny_y['target'], lasso.predict(val_tiny_X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
