{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic and SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import sklearn.datasets\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tiny_X = pd.read_csv('music_data/train_tiny_X.csv')\n",
    "train_tiny_y = pd.read_csv('music_data/train_tiny_Y.csv')\n",
    "\n",
    "train_X = pd.read_csv('new_data/new_train_X.csv')\n",
    "val_X = pd.read_csv('new_data/new_valid_X.csv')\n",
    "train_y = pd.read_csv('new_data/new_train_y.csv')\n",
    "val_y = pd.read_csv('new_data/new_valid_y.csv')\n",
    "\n",
    "test_X = pd.read_csv('new_data/new_test_X.csv')\n",
    "test_y = pd.read_csv('new_data/new_test_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2942719</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4875524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6589819</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1172060</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2069395</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4966246</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69897</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>933241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1122481</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2680592</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>767780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4214625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4641749</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>630040</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6231292</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2225845</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4878393</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22619</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5538879</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1943875</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3419483</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>365400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4732859</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2598070</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4951066</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2502689</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5289808</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>346709</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3266014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2631309</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>6046356</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>6191986</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>2383777</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>6853405</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>341327</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>6804646</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>77533</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>3572961</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>6111010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>3760788</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>557386</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>5642467</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>3233108</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>1392817</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>3349296</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>6692508</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>3088037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>3584620</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>3440369</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>565094</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>6602018</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>4430941</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>4477422</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>5611765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>1711155</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>779258</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>4950642</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4451788</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2824944</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>5168317</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  target\n",
       "0        2942719     0.0\n",
       "1        4875524     0.0\n",
       "2        6589819     0.0\n",
       "3        1172060     1.0\n",
       "4        2069395     0.0\n",
       "5        4966246     0.0\n",
       "6          69897     1.0\n",
       "7         933241     1.0\n",
       "8        1122481     1.0\n",
       "9        2680592     0.0\n",
       "10        767780     0.0\n",
       "11       4214625     1.0\n",
       "12       4641749     1.0\n",
       "13        630040     1.0\n",
       "14       6231292     0.0\n",
       "15       2225845     1.0\n",
       "16       4878393     0.0\n",
       "17         22619     0.0\n",
       "18       5538879     1.0\n",
       "19       1943875     0.0\n",
       "20       3419483     0.0\n",
       "21        365400     1.0\n",
       "22       4732859     0.0\n",
       "23       2598070     1.0\n",
       "24       4951066     1.0\n",
       "25       2502689     0.0\n",
       "26       5289808     1.0\n",
       "27        346709     1.0\n",
       "28       3266014     0.0\n",
       "29       2631309     0.0\n",
       "...          ...     ...\n",
       "9970     6046356     1.0\n",
       "9971     6191986     0.0\n",
       "9972     2383777     1.0\n",
       "9973     6853405     0.0\n",
       "9974      341327     0.0\n",
       "9975     6804646     0.0\n",
       "9976       77533     1.0\n",
       "9977     3572961     0.0\n",
       "9978     6111010     1.0\n",
       "9979     3760788     1.0\n",
       "9980      557386     1.0\n",
       "9981     5642467     1.0\n",
       "9982     3233108     0.0\n",
       "9983     1392817     1.0\n",
       "9984     3349296     0.0\n",
       "9985     6692508     1.0\n",
       "9986     3088037     0.0\n",
       "9987     3584620     0.0\n",
       "9988     3440369     0.0\n",
       "9989      565094     1.0\n",
       "9990     6602018     0.0\n",
       "9991     4430941     0.0\n",
       "9992     4477422     0.0\n",
       "9993     5611765     1.0\n",
       "9994     1711155     1.0\n",
       "9995      779258     1.0\n",
       "9996     4950642     1.0\n",
       "9997     4451788     0.0\n",
       "9998     2824944     0.0\n",
       "9999     5168317     0.0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_tiny_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5c6f36bbdfa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'music_data/train_X.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'music_data/valid_X.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'music_data/train_Y.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'music_data/valid_Y.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \"\"\"\n\u001b[1;32m    574\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_X = pd.read_csv('music_data/train_X.csv')\n",
    "val_X = pd.read_csv('music_data/valid_X.csv')\n",
    "train_y = pd.read_csv('music_data/train_Y.csv')\n",
    "val_y = pd.read_csv('music_data/valid_Y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tiny_X = val_X[:1000]\n",
    "val_tiny_y = val_y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "catCols = ['msno', 'song_id', 'source_screen_name', 'source_system_tab', 'source_type', 'genre_ids', 'artist_name', \n",
    "           'composer', 'lyricist', 'language', 'city', 'gender', 'registered_via']\n",
    "numCols = ['bd', 'song_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4426382 entries, 0 to 4426381\n",
      "Data columns (total 19 columns):\n",
      "Unnamed: 0                int64\n",
      "msno                      int64\n",
      "song_id                   int64\n",
      "source_screen_name        int64\n",
      "source_system_tab         int64\n",
      "source_type               int64\n",
      "song_length               float64\n",
      "genre_ids                 int64\n",
      "artist_name               int64\n",
      "composer                  int64\n",
      "lyricist                  int64\n",
      "language                  int64\n",
      "city                      int64\n",
      "bd                        int64\n",
      "gender                    int64\n",
      "registered_via            int64\n",
      "registration_init_time    object\n",
      "expiration_date           object\n",
      "time                      float64\n",
      "dtypes: float64(2), int64(15), object(2)\n",
      "memory usage: 641.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                0\n",
      "msno                      0\n",
      "song_id                   0\n",
      "source_screen_name        0\n",
      "source_system_tab         0\n",
      "source_type               0\n",
      "song_length               0\n",
      "genre_ids                 0\n",
      "artist_name               0\n",
      "composer                  0\n",
      "lyricist                  0\n",
      "language                  0\n",
      "city                      0\n",
      "bd                        0\n",
      "gender                    0\n",
      "registered_via            0\n",
      "registration_init_time    0\n",
      "expiration_date           0\n",
      "time                      0\n",
      "dtype: int64\n",
      "(4426382, 19)\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(train_X.isnull()))\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8852764, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train = pd.concat([train_X, train_y])\n",
    "all_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_y.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2942719</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4875524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6589819</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1172060</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2069395</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4966246</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69897</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>933241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1122481</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2680592</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>767780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4214625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4641749</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>630040</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6231292</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2225845</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4878393</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22619</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5538879</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1943875</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3419483</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>365400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4732859</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2598070</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4951066</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2502689</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5289808</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>346709</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3266014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2631309</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2517132</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3933461</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1494827</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>5094418</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4794417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6880648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6221463</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6735636</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>7274525</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4863915</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5034196</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2894160</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1378033</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5590211</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>560593</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2666876</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1599838</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>5234584</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2541661</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>403886</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>6692348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3280246</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5414876</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5136761</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>4360175</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4481392</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2165475</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6717786</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1653361</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6992592</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  target\n",
       "0      2942719     0.0\n",
       "1      4875524     0.0\n",
       "2      6589819     0.0\n",
       "3      1172060     1.0\n",
       "4      2069395     0.0\n",
       "5      4966246     0.0\n",
       "6        69897     1.0\n",
       "7       933241     1.0\n",
       "8      1122481     1.0\n",
       "9      2680592     0.0\n",
       "10      767780     0.0\n",
       "11     4214625     1.0\n",
       "12     4641749     1.0\n",
       "13      630040     1.0\n",
       "14     6231292     0.0\n",
       "15     2225845     1.0\n",
       "16     4878393     0.0\n",
       "17       22619     0.0\n",
       "18     5538879     1.0\n",
       "19     1943875     0.0\n",
       "20     3419483     0.0\n",
       "21      365400     1.0\n",
       "22     4732859     0.0\n",
       "23     2598070     1.0\n",
       "24     4951066     1.0\n",
       "25     2502689     0.0\n",
       "26     5289808     1.0\n",
       "27      346709     1.0\n",
       "28     3266014     0.0\n",
       "29     2631309     0.0\n",
       "..         ...     ...\n",
       "70     2517132     1.0\n",
       "71     3933461     0.0\n",
       "72     1494827     1.0\n",
       "73     5094418     0.0\n",
       "74     4794417     0.0\n",
       "75     6880648     0.0\n",
       "76     6221463     1.0\n",
       "77     6735636     0.0\n",
       "78     7274525     1.0\n",
       "79     4863915     1.0\n",
       "80     5034196     1.0\n",
       "81     2894160     1.0\n",
       "82     1378033     1.0\n",
       "83     5590211     0.0\n",
       "84      560593     1.0\n",
       "85     2666876     1.0\n",
       "86     1599838     0.0\n",
       "87     5234584     1.0\n",
       "88     2541661     0.0\n",
       "89      403886     1.0\n",
       "90     6692348     0.0\n",
       "91     3280246     0.0\n",
       "92     5414876     1.0\n",
       "93     5136761     0.0\n",
       "94     4360175     1.0\n",
       "95     4481392     1.0\n",
       "96     2165475     0.0\n",
       "97     6717786     1.0\n",
       "98     1653361     0.0\n",
       "99     6992592     0.0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train.dropna(axis=0, how='any').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numRow = len(all_data)\n",
    "# def checkCol(df, colName, numRow, isCata = True):\n",
    "#     print(colName, ':')\n",
    "#     print('Any NA?: ', df[colName].isnull().values.any())\n",
    "#     if df[colName].isnull().values.any():\n",
    "#         numNA = sum(df[colName].isnull().values)\n",
    "#         print ('    # of NA: ', numNA)\n",
    "#         print ('    NA%:     ', numNA/numRow)\n",
    "#     if isCata:\n",
    "#         levelList = df[colName].unique()\n",
    "#         print('Different levels: ', len(levelList), levelList)\n",
    "#         fillna(df, colName, isCata = True)\n",
    "        \n",
    "#     else:\n",
    "#         print('range: ', min(df[colName].astype(float).dropna()), max(df[colName].astype(float).dropna()))\n",
    "#         fillna(df, colName, isCata = False)\n",
    "        \n",
    "# def fillna(df, colName, isCata = True):\n",
    "#     if isCata:\n",
    "#         df[colName] = df[colName].fillna('0')\n",
    "#     else:\n",
    "#         if df[colName].isnull().values.any():\n",
    "#             df[colName+'_dm'] = df[colName].isnull().astype(int)\n",
    "#         df[colName] = df[colName].fillna(0)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score on training set:\n",
      "model score: 0.932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.93      4985\n",
      "         1.0       0.93      0.94      0.93      5015\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "0.9814634731712585\n"
     ]
    }
   ],
   "source": [
    "#debugging with tiny data set\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
    "                                               ('cat', categorical_transformer, catCols)])\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression())])\n",
    "\n",
    "clf.fit(train_tiny_X, train_tiny_y['target'])\n",
    "print(\"Model score on training set:\")\n",
    "print(\"model score: %.3f\" % clf.score(train_tiny_X, train_tiny_y['target']))\n",
    "print(classification_report(train_tiny_y['target'], clf.predict(train_tiny_X)))\n",
    "print(roc_auc_score(train_tiny_y['target'], clf.predict_proba(train_tiny_X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.62      0.62       477\n",
      "         1.0       0.65      0.65      0.65       523\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      1000\n",
      "   macro avg       0.63      0.63      0.63      1000\n",
      "weighted avg       0.63      0.63      0.63      1000\n",
      "\n",
      "0.6737737051601188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "print(\"Model score on validation set:\")\n",
    "print(\"model score: %.3f\" % clf.score(val_tiny_X, val_tiny_y['target']))\n",
    "print(classification_report(val_tiny_y['target'], clf.predict(val_tiny_X)))\n",
    "print(roc_auc_score(val_tiny_y['target'], clf.predict_proba(val_tiny_X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN IT YET!!!!!! HUGE DATASET!!!\n",
    "\n",
    "# numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "# categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "# preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
    "#                                                ('cat', categorical_transformer, catCols)])\n",
    "# clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                       ('classifier', LogisticRegression())])\n",
    "\n",
    "# clf.fit(train_X, train_y['target'])\n",
    "# print(\"model score: %.3f\" % clf.score(val_X, val_y['target']))\n",
    "# print(classification_report(val_y['target'], clf.predict(val_X)))\n",
    "# print(roc_auc_score(val_y, clf.predict_proba(val_X)['target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default: Logistic Regression with No Penalty, learning rate = 'optimal'  \n",
    "val acc = 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.94, NNZs: 146928, Bias: -0.001991, T: 495612, Avg. loss: 0.589471\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.21, NNZs: 146928, Bias: -0.002648, T: 991224, Avg. loss: 0.582975\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.45, NNZs: 146928, Bias: -0.002925, T: 1486836, Avg. loss: 0.580746\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.68, NNZs: 146928, Bias: -0.003182, T: 1982448, Avg. loss: 0.579014\n",
      "Total training time: 1.60 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.91, NNZs: 146928, Bias: -0.003247, T: 2478060, Avg. loss: 0.577507\n",
      "Total training time: 2.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.14, NNZs: 146928, Bias: -0.003372, T: 2973672, Avg. loss: 0.576164\n",
      "Total training time: 2.42 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2.18, NNZs: 146928, Bias: -0.003387, T: 3469284, Avg. loss: 0.575321\n",
      "Total training time: 2.83 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2.22, NNZs: 146928, Bias: -0.003413, T: 3964896, Avg. loss: 0.575078\n",
      "Total training time: 3.24 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2.27, NNZs: 146928, Bias: -0.003451, T: 4460508, Avg. loss: 0.574838\n",
      "Total training time: 3.65 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2.31, NNZs: 146928, Bias: -0.003492, T: 4956120, Avg. loss: 0.574602\n",
      "Total training time: 4.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 2.36, NNZs: 146928, Bias: -0.003473, T: 5451732, Avg. loss: 0.574369\n",
      "Total training time: 4.48 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 2.36, NNZs: 146928, Bias: -0.003472, T: 5947344, Avg. loss: 0.574212\n",
      "Total training time: 4.90 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2.37, NNZs: 146928, Bias: -0.003482, T: 6442956, Avg. loss: 0.574166\n",
      "Total training time: 5.33 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 2.38, NNZs: 146928, Bias: -0.003484, T: 6938568, Avg. loss: 0.574120\n",
      "Total training time: 5.75 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 2.39, NNZs: 146928, Bias: -0.003485, T: 7434180, Avg. loss: 0.574075\n",
      "Total training time: 6.16 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2.40, NNZs: 146928, Bias: -0.003484, T: 7929792, Avg. loss: 0.574029\n",
      "Total training time: 6.56 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2.40, NNZs: 146928, Bias: -0.003485, T: 8425404, Avg. loss: 0.573998\n",
      "Total training time: 6.97 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2.40, NNZs: 146928, Bias: -0.003487, T: 8921016, Avg. loss: 0.573989\n",
      "Total training time: 7.38 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 2.40, NNZs: 146928, Bias: -0.003487, T: 9416628, Avg. loss: 0.573980\n",
      "Total training time: 7.80 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 2.41, NNZs: 146928, Bias: -0.003488, T: 9912240, Avg. loss: 0.573971\n",
      "Total training time: 8.21 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 2.41, NNZs: 146928, Bias: -0.003489, T: 10407852, Avg. loss: 0.573962\n",
      "Total training time: 8.65 seconds.\n",
      "Convergence after 21 epochs took 8.74 seconds\n",
      "model score: 0.638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.62      0.63     45023\n",
      "         1.0       0.64      0.65      0.65     46757\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     91780\n",
      "   macro avg       0.64      0.64      0.64     91780\n",
      "weighted avg       0.64      0.64      0.64     91780\n",
      "\n",
      "0.6872296662210624\n"
     ]
    }
   ],
   "source": [
    "#mini batch training with full data and early stopping\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
    "                                               ('cat', categorical_transformer, catCols)])\n",
    "clf_log = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                ('classifier', SGDClassifier(loss='log', penalty=None, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, \n",
    "                                max_iter=1000, tol=0.001, shuffle=True, verbose=1, epsilon=0.1, n_jobs=None, \n",
    "                                random_state=None, learning_rate='adaptive', eta0=0.0001, \n",
    "                                power_t=0.5, early_stopping=True, validation_fraction=0.1, n_iter_no_change=5, \n",
    "                                class_weight=None, warm_start=True, average=False))])\n",
    "#default, no penalty\n",
    "clf_log.fit(train_X, train_y['target'])\n",
    "print(\"model score: %.3f\" % clf_log.score(val_X, val_y['target']))\n",
    "print(classification_report(val_y['target'], clf_log.predict(val_X)))\n",
    "print(roc_auc_score(val_y['target'], clf_log.predict_proba(val_X)[:,1]))\n",
    "#val acc 0.660\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.70      0.68     45023\n",
      "         1.0       0.70      0.66      0.68     46757\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     91780\n",
      "   macro avg       0.68      0.68      0.68     91780\n",
      "weighted avg       0.68      0.68      0.68     91780\n",
      "\n",
      "0.6812849767672813\n"
     ]
    }
   ],
   "source": [
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
    "                                               ('cat', categorical_transformer, catCols)])\n",
    "clf_svm = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                ('classifier', SGDClassifier(loss='hinge', penalty=None, early_stopping=True, \n",
    "                                             validation_fraction=0.1, n_iter_no_change=5))])\n",
    "#default, no penalty\n",
    "clf_svm.fit(train_X, train_y['target'])\n",
    "print(\"model score: %.3f\" % clf_svm.score(val_X, val_y['target']))\n",
    "print(classification_report(val_y['target'], clf_svm.predict(val_X)))\n",
    "print(roc_auc_score(val_y['target'], clf_svm.predict(val_X)>0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best SVM model(with no penalty):  \n",
    "learning rate = 'adaptive', eta = 0.01  \n",
    "best val acc = 0.697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta0: 0.01\n",
      "best val acc: 0.6981695358465897\n"
     ]
    }
   ],
   "source": [
    "etas = [0.01]\n",
    "best_model_svm = None\n",
    "best_model_score_svm = 0.0\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
    "                                               ('cat', categorical_transformer, catCols)])\n",
    "for eta in etas:\n",
    "    clf_svm = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                    ('classifier', SGDClassifier(loss='hinge', penalty=None, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, \n",
    "                                    max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, \n",
    "                                    random_state=None, learning_rate='adaptive', eta0=eta, \n",
    "                                    power_t=0.5, early_stopping=True, validation_fraction=0.1, n_iter_no_change=5, \n",
    "                                    class_weight=None, warm_start=True, average=False))])\n",
    "    clf_svm.fit(train_X, train_y['target'])\n",
    "    model_score = clf_svm.score(val_X, val_y['target'])\n",
    "    if model_score > best_model_score_svm:\n",
    "        best_model_score_svm = model_score\n",
    "        best_model_svm = clf_svm\n",
    "        print('eta0:',eta)\n",
    "        print('best val acc:',best_model_score_svm)\n",
    "                                        \n",
    "# print(\"best model score:\" ,best_model_score_svm)\n",
    "# print(classification_report(val_y['target'], best_model_svm.predict(val_X)))\n",
    "# print(roc_auc_score(val_y['target'], best_model_svm.predict(val_X)>0.5))\n",
    "#print(roc_auc_score(val_y['target'], clf_svm.predict_proba(val_X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model score: 0.6981695358465897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.69      0.69     45023\n",
      "         1.0       0.70      0.70      0.70     46757\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     91780\n",
      "   macro avg       0.70      0.70      0.70     91780\n",
      "weighted avg       0.70      0.70      0.70     91780\n",
      "\n",
      "0.6980930608338409\n"
     ]
    }
   ],
   "source": [
    "print(\"best model score:\" ,best_model_score_svm)\n",
    "print(classification_report(val_y['target'], best_model_svm.predict(val_X)))\n",
    "print(roc_auc_score(val_y['target'], best_model_svm.predict(val_X)>0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best logistic regression model(with no penalty):  \n",
    "learning rate = 'adaptive', eta = 0.01  \n",
    "best val acc = 0.694"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: optimal eta0: 0.01\n",
      "best val acc: 0.677260841141861\n",
      "learning_rate: adaptive eta0: 0.01\n",
      "best val acc: 0.6955872739158858\n",
      "best model score: 0.6955872739158858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.69      0.69     45023\n",
      "         1.0       0.70      0.70      0.70     46757\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     91780\n",
      "   macro avg       0.70      0.70      0.70     91780\n",
      "weighted avg       0.70      0.70      0.70     91780\n",
      "\n",
      "0.7630735829335613\n"
     ]
    }
   ],
   "source": [
    "#fine tune learning rate on logistic regression\n",
    "best_model_df = None\n",
    "best_model_score_df = 0.0\n",
    "learning_rate = ['optimal','invscaling','adaptive']\n",
    "etas = [0.01,0.001,0.0001]\n",
    "for lr in learning_rate:\n",
    "    for eta in etas:\n",
    "        clf_log_df = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', SGDClassifier(loss='log', penalty=None, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, \n",
    "                                        max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, \n",
    "                                        random_state=None, learning_rate=lr, eta0=eta, \n",
    "                                        power_t=0.5, early_stopping=True, validation_fraction=0.1, n_iter_no_change=5, \n",
    "                                        class_weight=None, warm_start=True, average=False))])\n",
    "        clf_log_df.fit(train_X, train_y['target'])\n",
    "        model_score = clf_log_df.score(val_X, val_y['target'])\n",
    "        if model_score > best_model_score_df:\n",
    "            best_model_score_df = model_score\n",
    "            best_model_df = clf_log_df\n",
    "            print('learning_rate:',lr,'eta0:',eta)\n",
    "            print('best val acc:',best_model_score_df)\n",
    "                                        \n",
    "print(\"best model score:\" ,best_model_score_df)\n",
    "print(classification_report(val_y['target'], best_model_df.predict(val_X)))\n",
    "print(roc_auc_score(val_y['target'], best_model_df.predict_proba(val_X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = best_model_df.predict_proba(test_X)[:,1]\n",
    "y_pred_val = best_model_df.predict_proba(val_X)[:,1]\n",
    "\n",
    "np.savez('output/logistic_results.npz', val_target=val_y['target'], val_preds= y_pred_val, test_target = test_y['target'], test_preds=y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: log penalty: l1 val acc: 0.6581717149705818\n",
      "best loss: log best penalty: l1 best val acc: 0.6581717149705818\n",
      "loss: log penalty: l2 val acc: 0.6827740248420135\n",
      "best loss: log best penalty: l2 best val acc: 0.6827740248420135\n",
      "loss: log penalty: elasticnet val acc: 0.6761712791457833\n",
      "loss: hinge penalty: l1 val acc: 0.656123338417956\n",
      "loss: hinge penalty: l2 val acc: 0.6737088690346481\n",
      "loss: hinge penalty: elasticnet val acc: 0.6649269993462628\n",
      "best model score: 0.6827740248420135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.66      0.67     45023\n",
      "         1.0       0.68      0.71      0.69     46757\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     91780\n",
      "   macro avg       0.68      0.68      0.68     91780\n",
      "weighted avg       0.68      0.68      0.68     91780\n",
      "\n",
      "0.7485156067340346\n"
     ]
    }
   ],
   "source": [
    "#fine tune SVM and Logistic regression with penalty\n",
    "best_model = None\n",
    "best_model_score = 0.0\n",
    "loss = ['log', 'hinge']\n",
    "penalty = ['l1','l2','elasticnet']\n",
    "\n",
    "for ls in loss:\n",
    "    for plty in penalty: \n",
    "        clf_log_tune = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', SGDClassifier(loss=ls, penalty=plty, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, \n",
    "                                        max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, \n",
    "                                        random_state=None, learning_rate='adaptive', eta0=0.01, \n",
    "                                        power_t=0.5, early_stopping=True, validation_fraction=0.1, n_iter_no_change=5, \n",
    "                                        class_weight=None, warm_start=True, average=False))])\n",
    "        clf_log_tune.fit(train_X, train_y['target'])\n",
    "        model_score = clf_log_tune.score(val_X, val_y['target'])\n",
    "        print( 'loss:', ls, 'penalty:', plty,'val acc:', model_score)\n",
    "        if model_score > best_model_score:\n",
    "            best_model_score = model_score\n",
    "            best_model = clf_log_tune\n",
    "            print( 'best loss:', ls, 'best penalty:', plty,'best val acc:', model_score)\n",
    "\n",
    "print(\"best model score:\" ,best_model_score)\n",
    "print(classification_report(val_y['target'], best_model.predict(val_X)))\n",
    "print(roc_auc_score(val_y['target'], best_model.predict_proba(val_X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8945710cedbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#rbf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_approximation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRBFSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnumeric_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scaler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcategorical_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'onehot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "#rbf\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
    "                                               ('cat', categorical_transformer, catCols)])\n",
    "rbf_feature = RBFSampler(gamma=0.2, random_state=1)\n",
    "clf_kernel = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                ('kernel',rbf_feature),\n",
    "                ('classifier', SGDClassifier(loss='hinge', penalty=None, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, \n",
    "                                max_iter=1000, tol=0.001, shuffle=True, verbose=1, epsilon=0.1, n_jobs=None, \n",
    "                                random_state=None, learning_rate='adaptive', eta0=0.01, \n",
    "                                power_t=0.5, early_stopping=True, validation_fraction=0.1, n_iter_no_change=5))])\n",
    "#default, no penalty\n",
    "clf_kernel.fit(train_tiny_X, train_tiny_y['target'])\n",
    "print(\"model score: %.3f\" % clf_kernel.score(val_tiny_X, val_tiny_y['target']))\n",
    "print(classification_report(val_tiny_y['target'], clf_kernel.predict(val_tiny_X)))\n",
    "#print(roc_auc_score(val_tiny_y['target'], clf_kernel.predict_proba(val_tiny_X)[:,1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.660\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.69      0.71      4985\n",
      "         1.0       0.71      0.73      0.72      5015\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.71      0.71      0.71     10000\n",
      "weighted avg       0.71      0.71      0.71     10000\n",
      "\n",
      "0.7882900546104915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numCols),\n",
    "                                               ('cat', categorical_transformer, catCols)])\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(penalty='l1'))])\n",
    "\n",
    "clf.fit(train_tiny_X, train_tiny_y['target'])\n",
    "print(\"model score: %.3f\" % clf.score(val_tiny_X, val_tiny_y['target']))\n",
    "print(classification_report(train_tiny_y['target'], clf.predict(train_tiny_X)))\n",
    "print(roc_auc_score(train_tiny_y['target'], clf.predict_proba(train_tiny_X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.660\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.65      0.65       477\n",
      "         1.0       0.68      0.67      0.67       523\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      1000\n",
      "   macro avg       0.66      0.66      0.66      1000\n",
      "weighted avg       0.66      0.66      0.66      1000\n",
      "\n",
      "0.6840073595728562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "print(\"model score: %.3f\" % clf.score(val_tiny_X, val_tiny_y['target']))\n",
    "print(classification_report(val_tiny_y['target'], clf.predict(val_tiny_X)))\n",
    "print(roc_auc_score(val_tiny_y['target'], clf.predict_proba(val_tiny_X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_names_from_ColumnTransformer(column_transformer):    \n",
    "    col_name = []\n",
    "    for transformer_in_columns in column_transformer.transformers_[:]:#the last transformer is ColumnTransformer's 'remainder'\n",
    "        raw_col_name = transformer_in_columns[2]\n",
    "        if isinstance(transformer_in_columns[1],Pipeline): \n",
    "            transformer = transformer_in_columns[1].steps[-1][1]\n",
    "        else:\n",
    "            transformer = transformer_in_columns[1]\n",
    "        try:\n",
    "            names = transformer.get_feature_names()\n",
    "        except AttributeError: # if no 'get_feature_names' function, use raw column name\n",
    "            names = raw_col_name\n",
    "        if isinstance(names,np.ndarray): # eg.\n",
    "            col_name += names.tolist()\n",
    "        elif isinstance(names,list):\n",
    "            col_name += names    \n",
    "        elif isinstance(names,str):\n",
    "            col_name.append(names)\n",
    "    return col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = clf.named_steps['classifier'].coef_\n",
    "feature_names = get_column_names_from_ColumnTransformer(clf.named_steps['preprocessor'])\n",
    "for i in range(len(feature_names)):\n",
    "    if feature_names[i][0] == 'x':\n",
    "        flag = i\n",
    "        break\n",
    "cat_names = feature_names[flag:]\n",
    "select = []\n",
    "for i in range(coef.shape[1]):\n",
    "    if coef[0,i] != 0:\n",
    "        select.append(i)\n",
    "select_features = [feature_names[i] for i in select]\n",
    "len(select_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(select_features)):\n",
    "    if select_features[i][0] == 'x':\n",
    "        flag = i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_select = select_features[:flag]\n",
    "cat_select = select_features[flag:]\n",
    "inds = []\n",
    "for i in range(len(cat_select)):\n",
    "    inds.append(cat_names.index(cat_select[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.93      4985\n",
      "         1.0       0.93      0.94      0.93      5015\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "0.9814643531791786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(penalty='l2'))])\n",
    "\n",
    "clf.fit(train_tiny_X, train_tiny_y['target'])\n",
    "print(\"model score: %.3f\" % clf.score(val_tiny_X, val_tiny_y['target']))\n",
    "print(classification_report(train_tiny_y['target'], clf.predict(train_tiny_X)))\n",
    "print(roc_auc_score(train_tiny_y['target'], clf.predict_proba(train_tiny_X)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.62      0.62       477\n",
      "         1.0       0.65      0.65      0.65       523\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      1000\n",
      "   macro avg       0.63      0.63      0.63      1000\n",
      "weighted avg       0.63      0.63      0.63      1000\n",
      "\n",
      "0.6737737051601188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "print(\"model score: %.3f\" % clf.score(val_tiny_X, val_tiny_y['target']))\n",
    "print(classification_report(val_tiny_y['target'], clf.predict(val_tiny_X)))\n",
    "print(roc_auc_score(val_tiny_y['target'], clf.predict_proba(val_tiny_X)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting & Decision Tree\n",
    "Moved to \"Tree & Boosting\" Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48453905786700674\n",
      "alpha: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49497671219414635\n",
      "alpha: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49993324554384255\n",
      "alpha: 0.2\n",
      "0.49993324554384255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs229/.local/lib/python3.5/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "alphas = [0.01,0.05,0.1,0.2]\n",
    "for a in alphas:\n",
    "    print('alpha: {}'.format(a))\n",
    "    lasso = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor',  Lasso(alpha = a))])\n",
    "    lasso.fit(train_tiny_X, train_tiny_y['target'])\n",
    "    print(np.sqrt(metrics.mean_squared_error(val_tiny_y['target'], lasso.predict(val_tiny_X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
