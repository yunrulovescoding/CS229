{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchvision import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,classification_report,roc_auc_score\n",
    "#from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = pd.read_csv('music_data/train_X.csv')\n",
    "train_X = pd.read_csv('music_data/train_X_date_converted.csv')\n",
    "train_y = pd.read_csv('music_data/train_Y.csv')\n",
    "\n",
    "# val_X = pd.read_csv('music_data/valid_X.csv')\n",
    "val_X = pd.read_csv('music_data/valid_X_date_converted.csv')\n",
    "val_y = pd.read_csv('music_data/valid_Y.csv')\n",
    "\n",
    "# test_X = pd.read_csv('music_data/test_X.csv')\n",
    "test_X = pd.read_csv('music_data/test_X_date_converted.csv')\n",
    "test_y = pd.read_csv('music_data/test_Y.csv')\n",
    "\n",
    "# train_tiny_X = pd.read_csv('music_data/train_tiny_X.csv')\n",
    "train_tiny_X = pd.read_csv('music_data/train_tiny_X_date_converted.csv')\n",
    "train_tiny_y = pd.read_csv('music_data/train_tiny_Y.csv')\n",
    "\n",
    "# val_tiny_X = val_X[:1000].copy()\n",
    "val_tiny_X = pd.read_csv('music_data/val_tiny_X_date_converted.csv')\n",
    "val_tiny_y = val_y[:1000].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "MAX_EPOCH = 20\n",
    "SAVE_THRESHOLD = 0.6\n",
    "SAVE_LOGITS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2942719</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4875524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6589819</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1172060</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2069395</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  target\n",
       "0     2942719     0.0\n",
       "1     4875524     0.0\n",
       "2     6589819     0.0\n",
       "3     1172060     1.0\n",
       "4     2069395     0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.target.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, dfX, dfy):\n",
    "        #'Initialization'\n",
    "        self.dfX = dfX\n",
    "        self.dfy = dfy\n",
    "    def __len__(self):\n",
    "        #'Denotes the total number of samples'\n",
    "        return len(self.dfX)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #'Generates one sample of data'\n",
    "        # Load data and get label\n",
    "        X = self.dfX.iloc[index]\n",
    "        X = torch.tensor(X)\n",
    "        y = self.dfy.target.iloc[index]\n",
    "        y = torch.tensor(y)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 4.8755e+06, 5.2240e+03, 1.4524e+05, 1.6000e+01, 6.0000e+00,\n",
       "        8.0000e+00, 2.0062e+05, 3.7100e+02, 3.4892e+04, 7.4276e+04, 2.6024e+04,\n",
       "        6.0000e+00, 3.0000e+00, 4.1000e+01, 1.0000e+00, 2.0000e+00, 4.9078e-01,\n",
       "        5.0000e+03, 6.4750e+03])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(train_X.iloc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 [0]\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(20,40),\n",
    "    nn.BatchNorm1d(40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40,60),\n",
    "    nn.BatchNorm1d(60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(60,60),\n",
    "    nn.BatchNorm1d(60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(60,1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "device, gpu_ids = utils.get_available_devices()\n",
    "print(device,gpu_ids)\n",
    "model = nn.DataParallel(model, gpu_ids)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "#criterion = torch.nn.BCEWithLogitsLoss()   # default\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=L2_PENALTY)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, nesterov=True)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=4, min_lr=3e-5, verbose=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=4, \n",
    "                                                       min_lr=1e-4, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion):\n",
    "    model.eval();\n",
    "    test_loss = 0.0\n",
    "    true_ans_list = []\n",
    "    preds_cat = []\n",
    "    logits_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (features, targets) in enumerate(test_loader):\n",
    "            features, targets = cuda(features), cuda(targets)\n",
    "            logits = model(features)         \n",
    "            loss = criterion(logits, targets)\n",
    "            test_loss += loss.item()\n",
    "            true_ans_list.append(targets)\n",
    "            preds_cat.append(torch.sigmoid(logits))\n",
    "            logits=logits.cpu().numpy()\n",
    "            logits_list.append(logits)\n",
    "\n",
    "        all_true_ans = torch.cat(true_ans_list)\n",
    "        all_preds = torch.cat(preds_cat)\n",
    "        all_preds = torch.ge(all_preds, 0.5)\n",
    "        all_true_ans=all_true_ans.cpu()\n",
    "        all_preds=all_preds.cpu()\n",
    "        f1_eval = f1_score(all_true_ans, all_preds, average='weighted')\n",
    "        f1_each = f1_score(all_true_ans, all_preds, average=None)\n",
    "        # drop the last logits_list\n",
    "        logits_list = logits_list[:-1]\n",
    "        # print(\"list:\", logits_list)\n",
    "        all_logits = np.stack(logits_list)\n",
    "\n",
    "    return all_logits, all_true_ans, all_preds\n",
    "\n",
    "\n",
    "def validate(model, valid_loader, criterion):\n",
    "    model.eval();\n",
    "    test_loss = 0.0\n",
    "    true_ans_list = []\n",
    "    preds_cat = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        valid_iterator = valid_loader\n",
    "\n",
    "        for step, (features, targets) in enumerate(valid_loader):\n",
    "            features, targets = cuda(features), cuda(targets)\n",
    "            logits = model(features)\n",
    "\n",
    "            loss = criterion(logits, targets)\n",
    "            test_loss += loss.item()\n",
    "            true_ans_list.append(targets)\n",
    "            preds_cat.append(torch.sigmoid(logits))\n",
    "\n",
    "        all_true_ans = torch.cat(true_ans_list)\n",
    "        all_preds = torch.cat(preds_cat)\n",
    "        all_preds = torch.ge(all_preds, 0.5)\n",
    "        all_true_ans=all_true_ans.cpu()\n",
    "        all_preds=all_preds.cpu()\n",
    "        # f1_eval = f1_score(all_true_ans, all_preds).item()\n",
    "        f1_eval = f1_score(all_true_ans, all_preds, average='weighted')\n",
    "        f1_each = f1_score(all_true_ans, all_preds, average=None)\n",
    "\n",
    "    return test_loss / (step + 1), f1_eval, f1_each\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda(x):\n",
    "    return x.cuda(non_blocking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN - Draft & Debugging on tiny dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_tiny = myDataset(train_tiny_X,train_tiny_y)\n",
    "val_dataset_tiny = myDataset(val_tiny_X, val_tiny_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tiny_loader = DataLoader(train_dataset_tiny, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_tiny_loader = DataLoader(val_dataset_tiny, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/625 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Epoch: 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /pytorch/aten/src/THC/generic/THCTensorMath.cu:26",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-501e6695e1ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /pytorch/aten/src/THC/generic/THCTensorMath.cu:26"
     ]
    }
   ],
   "source": [
    "train_loss_history = []\n",
    "train_epoch_losses = []\n",
    "valid_losses = []\n",
    "valid_f1s = []\n",
    "best_model_f1 = 0.0\n",
    "best_model_f1_each = []  # f1 for each label\n",
    "best_model = None\n",
    "best_model_ep = 0\n",
    "num_ = len(os.listdir('output/')) + 1\n",
    "\n",
    "for epoch in range(1, MAX_EPOCH + 1):\n",
    "    #log.info('Starting epoch {}...'.format(epoch))\n",
    "    print('starting Epoch:',epoch)\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    train_tqdm = tqdm(train_tiny_loader)\n",
    "    train_loss_curr_epoch = []\n",
    "\n",
    "    for step, (features, targets) in enumerate(train_tqdm):\n",
    "\n",
    "        features = features.to(device=device) # move to device, e.g. GPU\n",
    "        targets = targets.to(device=device, dtype=torch.long)\n",
    "\n",
    "        features, targets = cuda(features), cuda(targets)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(features)  \n",
    "\n",
    "        loss = criterion(logits, targets)            \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if (step+1) % LOSS_HIST_ACCUM_FREQ == 0:\n",
    "            tr_loss_ = total_loss / step\n",
    "#             if (step+1) % (LOSS_HIST_ACCUM_FREQ*4) == 0:\n",
    "#                 log.info('Train loss on iter {} : {}'.format((step+1), round(tr_loss_, 6)))\n",
    "\n",
    "            train_loss_history.append(tr_loss_)\n",
    "            train_loss_curr_epoch.append(tr_loss_)\n",
    "\n",
    "    avg_epoch_loss = np.mean(train_loss_curr_epoch)\n",
    "    #log.info('Mean train loss: {}'.format(round(avg_epoch_loss, 6)))\n",
    "    print('mean train loss:', avg_epoch_loss)\n",
    "    train_epoch_losses.append(avg_epoch_loss)\n",
    "\n",
    "    print('Evaluating...')\n",
    "    valid_loss, valid_f1, valid_f1_each = validate(model, val_tiny_loader, criterion)\n",
    "    print('Validation loss:',(round(valid_loss, 6)))\n",
    "    print('Validation F1: ',(round(valid_f1, 5)))\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    valid_f1s.append(valid_f1)\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    # train_tqdm.set_postfix(epoch=epoch, loss=avg_epoch_loss)      \n",
    "\n",
    "    if valid_f1 >= best_model_f1:\n",
    "        best_model = model\n",
    "        best_model_f1 = valid_f1\n",
    "        best_model_ep = epoch\n",
    "        best_model_f1_each = valid_f1_each\n",
    "\n",
    "    if (epoch > 3) and (epoch % 4 == 0) and best_model_f1 > SAVE_THRESHOLD:\n",
    "        #log.info('Saving best model ({})...'.format(num_))\n",
    "        model_pt = 'output/best_model{}.pt'.format(num_)\n",
    "        torch.save(best_model, model_pt)\n",
    "\n",
    "    if (epoch > 3) and SAVE_RESULTS:\n",
    "        results_dict = dict()\n",
    "        results_dict['train_loss_history'] = train_loss_history\n",
    "        results_dict['valid_loss'] = valid_losses\n",
    "        results_dict['valid_f1'] = valid_f1s\n",
    "        results_dict['best_valid_f1_each_label'] = best_model_f1_each.tolist()\n",
    "        results_path = 'output/results{}.json'.format(num_)\n",
    "        with open(results_path, 'w') as fp:\n",
    "            json.dump(results_dict, fp, indent=4)\n",
    "\n",
    "    if (epoch > 7) and (utils.check_early_stopping(valid_losses, patience=6, threshold=3e-3)):\n",
    "        #log.info('Early stopping...')\n",
    "        break\n",
    "\n",
    "print()\n",
    "log.info('Best F1 is {} on epoch {}'.format(round(best_model_f1, 5), best_model_ep))\n",
    "print('Best F1_each is {} on epoch {}'.format(best_model_f1_each.tolist(), best_model_ep))\n",
    "\n",
    "\n",
    "# Save model (remember to change model name)\n",
    "if best_model_f1 > SAVE_THRESHOLD:\n",
    "    #log.info('Saving best model...')\n",
    "    torch.save(best_model, 'output/best_model{}.pt'.format(num_))\n",
    "\n",
    "if SAVE_LOGITS:\n",
    "    #log.info('Saving test set info...')\n",
    "    test_logits, test_true_ans, test_preds = test(best_model, test_loader, criterion)\n",
    "    # test_logits = test_logits.cpu().numpy()\n",
    "    test_true_ans = test_true_ans.cpu().numpy()\n",
    "    test_preds = test_preds.cpu().numpy()\n",
    "    test_path = 'output/test_results{}.npz'.format(num_)\n",
    "    np.savez(test_path, test_logits=test_logits, test_true_ans=test_true_ans, test_preds=test_preds)\n",
    "\n",
    "# Load weights\n",
    "if LOAD_MODEL:\n",
    "    model_path = 'output/best_model3.pt'\n",
    "    #log.info('Loading weights from {}...'.format(model_path))\n",
    "\n",
    "    # model.load_state_dict(torch.load('output/saved/best_model1.pt'))\n",
    "    model = torch.load(model_path)\n",
    "    model.to(device)\n",
    "    # model.eval()\n",
    "    # valid_loss, valid_f1 = validate(model, test_loader, criterion, need_tqdm=False)\n",
    "\n",
    "if SAVE_PLOT:\n",
    "    xs = list(range(1, len(train_epoch_losses) + 1))\n",
    "    plt.title('Loss')\n",
    "    plt.plot(xs, train_epoch_losses, '-o', label = 'train')\n",
    "    plt.plot(xs, valid_losses, '-o', label = 'valid')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig('output/train_val_loss_dense{}.png'.format(num_))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.title('F1')\n",
    "    plt.plot(xs, valid_f1s, '-o')\n",
    "    plt.ylabel('Valid F1')\n",
    "    plt.xticks(xs);\n",
    "    plt.xlabel('epoch');\n",
    "    plt.savefig('output/valid_f1{}.png'.format(num_))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN - Full dataset w/o tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN - Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
