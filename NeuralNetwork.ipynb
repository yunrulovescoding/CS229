{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import category_encoders as ce\n",
    "#from torchvision import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,classification_report,roc_auc_score\n",
    "#from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = pd.read_csv('music_data/train_X.csv')\n",
    "train_X = pd.read_csv('music_data/train_X_date_converted.csv')\n",
    "train_y = pd.read_csv('music_data/train_Y.csv')\n",
    "\n",
    "# val_X = pd.read_csv('music_data/valid_X.csv')\n",
    "val_X = pd.read_csv('music_data/valid_X_date_converted.csv')\n",
    "val_y = pd.read_csv('music_data/valid_Y.csv')\n",
    "\n",
    "# test_X = pd.read_csv('music_data/test_X.csv')\n",
    "test_X = pd.read_csv('music_data/test_X_date_converted.csv')\n",
    "test_y = pd.read_csv('music_data/test_Y.csv')\n",
    "\n",
    "# # train_tiny_X = pd.read_csv('music_data/train_tiny_X.csv')\n",
    "# train_tiny_X = pd.read_csv('music_data/train_tiny_X_date_converted.csv')\n",
    "# train_tiny_y = pd.read_csv('music_data/train_tiny_Y.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tiny_X=train_X[:10000].copy()\n",
    "train_tiny_y = train_y[:10000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_tiny_X = val_X[:1000].copy()\n",
    "val_tiny_X = val_X[:1024].copy()\n",
    "val_tiny_y = val_y[:1024].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.target.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "catCols = ['msno', 'song_id', 'source_screen_name', 'source_system_tab', 'source_type', 'genre_ids', 'artist_name', \n",
    "           'composer', 'lyricist', 'language', 'city', 'gender', 'registered_via']\n",
    "numCols = ['Unnamed: 0','Unnamed: 0.1','bd', 'song_length','time','registration_init_time_int','expiration_date_int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# train_X_catCols = train_tiny_X[catCols].values\n",
    "# train_X_catCols = OneHotEncoder().fit_transform(train_X_catCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 7)\n",
      "(10000, 7)\n"
     ]
    }
   ],
   "source": [
    "train_X_numCols = train_tiny_X[numCols].values\n",
    "print(train_X_numCols.shape)\n",
    "train_X_numCols = StandardScaler().fit_transform(train_X_numCols)\n",
    "print(train_X_numCols.shape)\n",
    "train_tiny_X[numCols] = train_X_numCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>msno</th>\n",
       "      <th>song_id</th>\n",
       "      <th>source_screen_name</th>\n",
       "      <th>source_system_tab</th>\n",
       "      <th>source_type</th>\n",
       "      <th>song_length</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>composer</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>language</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>time</th>\n",
       "      <th>registration_init_time_int</th>\n",
       "      <th>expiration_date_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.731878</td>\n",
       "      <td>-0.356394</td>\n",
       "      <td>8145</td>\n",
       "      <td>253733</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.428309</td>\n",
       "      <td>371</td>\n",
       "      <td>4252</td>\n",
       "      <td>8389</td>\n",
       "      <td>2681</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.650309</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.356394</td>\n",
       "      <td>1.201362</td>\n",
       "      <td>-2.210220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.731531</td>\n",
       "      <td>0.553126</td>\n",
       "      <td>5224</td>\n",
       "      <td>145235</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.796309</td>\n",
       "      <td>371</td>\n",
       "      <td>34892</td>\n",
       "      <td>74276</td>\n",
       "      <td>26024</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.873194</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.553126</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.005168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.731185</td>\n",
       "      <td>1.359821</td>\n",
       "      <td>5474</td>\n",
       "      <td>22231</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.563420</td>\n",
       "      <td>371</td>\n",
       "      <td>20609</td>\n",
       "      <td>27775</td>\n",
       "      <td>9110</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.650309</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.359821</td>\n",
       "      <td>1.162370</td>\n",
       "      <td>-0.304510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.730838</td>\n",
       "      <td>-1.189612</td>\n",
       "      <td>23177</td>\n",
       "      <td>70181</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>371</td>\n",
       "      <td>44425</td>\n",
       "      <td>83027</td>\n",
       "      <td>34734</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.650309</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.189612</td>\n",
       "      <td>0.283693</td>\n",
       "      <td>0.187798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.730492</td>\n",
       "      <td>-0.767353</td>\n",
       "      <td>3269</td>\n",
       "      <td>128141</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.219789</td>\n",
       "      <td>371</td>\n",
       "      <td>42400</td>\n",
       "      <td>81151</td>\n",
       "      <td>32836</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.650309</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.767353</td>\n",
       "      <td>-0.430856</td>\n",
       "      <td>-1.582924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1   msno  song_id  source_screen_name  \\\n",
       "0   -1.731878     -0.356394   8145   253733                  16   \n",
       "1   -1.731531      0.553126   5224   145235                  16   \n",
       "2   -1.731185      1.359821   5474    22231                  11   \n",
       "3   -1.730838     -1.189612  23177    70181                   8   \n",
       "4   -1.730492     -0.767353   3269   128141                  12   \n",
       "\n",
       "   source_system_tab  source_type  song_length  genre_ids  artist_name  \\\n",
       "0                  6            8     0.428309        371         4252   \n",
       "1                  6            8    -0.796309        371        34892   \n",
       "2                  0            7    -0.563420        371        20609   \n",
       "3                  3            3     0.331818        371        44425   \n",
       "4                  2            2     1.219789        371        42400   \n",
       "\n",
       "   composer  lyricist  language  city        bd  gender  registered_via  \\\n",
       "0      8389      2681         9     0 -0.650309       2               1   \n",
       "1     74276     26024         6     3  0.873194       1               2   \n",
       "2     27775      9110         9     0 -0.650309       2               1   \n",
       "3     83027     34734         2     0 -0.650309       2               0   \n",
       "4     81151     32836         2     0 -0.650309       2               2   \n",
       "\n",
       "       time  registration_init_time_int  expiration_date_int  \n",
       "0 -0.356394                    1.201362            -2.210220  \n",
       "1  0.553126                    0.119565             0.005168  \n",
       "2  1.359821                    1.162370            -0.304510  \n",
       "3 -1.189612                    0.283693             0.187798  \n",
       "4 -0.767353                   -0.430856            -1.582924  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tiny_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X_catCols = train_tiny_X[catCols]\n",
    "# train_X_catCols = OneHotEncoder().fit_transform(train_X_catCols)\n",
    "# print(train_X_catCols.shape,train_X_numCols.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X_catCols = np.array(train_X_catCols)\n",
    "# train_X_numCols = np.array(train_X_numCols)\n",
    "# print(train_X_catCols)\n",
    "#train_all = np.concatenate((train_X_numCols,train_X_catCols),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>song_id</th>\n",
       "      <th>source_screen_name</th>\n",
       "      <th>source_system_tab</th>\n",
       "      <th>source_type</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>composer</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>language</th>\n",
       "      <th>city</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8145</td>\n",
       "      <td>253733</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>371</td>\n",
       "      <td>4252</td>\n",
       "      <td>8389</td>\n",
       "      <td>2681</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5224</td>\n",
       "      <td>145235</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>371</td>\n",
       "      <td>34892</td>\n",
       "      <td>74276</td>\n",
       "      <td>26024</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5474</td>\n",
       "      <td>22231</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>371</td>\n",
       "      <td>20609</td>\n",
       "      <td>27775</td>\n",
       "      <td>9110</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23177</td>\n",
       "      <td>70181</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>371</td>\n",
       "      <td>44425</td>\n",
       "      <td>83027</td>\n",
       "      <td>34734</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3269</td>\n",
       "      <td>128141</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>371</td>\n",
       "      <td>42400</td>\n",
       "      <td>81151</td>\n",
       "      <td>32836</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    msno  song_id  source_screen_name  source_system_tab  source_type  \\\n",
       "0   8145   253733                  16                  6            8   \n",
       "1   5224   145235                  16                  6            8   \n",
       "2   5474    22231                  11                  0            7   \n",
       "3  23177    70181                   8                  3            3   \n",
       "4   3269   128141                  12                  2            2   \n",
       "\n",
       "   genre_ids  artist_name  composer  lyricist  language  city  gender  \\\n",
       "0        371         4252      8389      2681         9     0       2   \n",
       "1        371        34892     74276     26024         6     3       1   \n",
       "2        371        20609     27775      9110         9     0       2   \n",
       "3        371        44425     83027     34734         2     0       2   \n",
       "4        371        42400     81151     32836         2     0       2   \n",
       "\n",
       "   registered_via  \n",
       "0               1  \n",
       "1               2  \n",
       "2               1  \n",
       "3               0  \n",
       "4               2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = ce.OneHotEncoder(handle_unknown='ignore', use_cat_names=True)\n",
    "train_X_catCols = ohe.fit_transform(train_tiny_X[catCols])\n",
    "train_X_catCols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train_X_catCols.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>msno</th>\n",
       "      <th>song_id</th>\n",
       "      <th>source_screen_name</th>\n",
       "      <th>source_system_tab</th>\n",
       "      <th>source_type</th>\n",
       "      <th>song_length</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>composer</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>language</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>time</th>\n",
       "      <th>registration_init_time_int</th>\n",
       "      <th>expiration_date_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.731878</td>\n",
       "      <td>-0.356394</td>\n",
       "      <td>8145</td>\n",
       "      <td>253733</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.428309</td>\n",
       "      <td>371</td>\n",
       "      <td>4252</td>\n",
       "      <td>8389</td>\n",
       "      <td>2681</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.650309</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.356394</td>\n",
       "      <td>1.201362</td>\n",
       "      <td>-2.210220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.731531</td>\n",
       "      <td>0.553126</td>\n",
       "      <td>5224</td>\n",
       "      <td>145235</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.796309</td>\n",
       "      <td>371</td>\n",
       "      <td>34892</td>\n",
       "      <td>74276</td>\n",
       "      <td>26024</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.873194</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.553126</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.005168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.731185</td>\n",
       "      <td>1.359821</td>\n",
       "      <td>5474</td>\n",
       "      <td>22231</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.563420</td>\n",
       "      <td>371</td>\n",
       "      <td>20609</td>\n",
       "      <td>27775</td>\n",
       "      <td>9110</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.650309</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.359821</td>\n",
       "      <td>1.162370</td>\n",
       "      <td>-0.304510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.730838</td>\n",
       "      <td>-1.189612</td>\n",
       "      <td>23177</td>\n",
       "      <td>70181</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>371</td>\n",
       "      <td>44425</td>\n",
       "      <td>83027</td>\n",
       "      <td>34734</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.650309</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.189612</td>\n",
       "      <td>0.283693</td>\n",
       "      <td>0.187798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.730492</td>\n",
       "      <td>-0.767353</td>\n",
       "      <td>3269</td>\n",
       "      <td>128141</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.219789</td>\n",
       "      <td>371</td>\n",
       "      <td>42400</td>\n",
       "      <td>81151</td>\n",
       "      <td>32836</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.650309</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.767353</td>\n",
       "      <td>-0.430856</td>\n",
       "      <td>-1.582924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1   msno  song_id  source_screen_name  \\\n",
       "0   -1.731878     -0.356394   8145   253733                  16   \n",
       "1   -1.731531      0.553126   5224   145235                  16   \n",
       "2   -1.731185      1.359821   5474    22231                  11   \n",
       "3   -1.730838     -1.189612  23177    70181                   8   \n",
       "4   -1.730492     -0.767353   3269   128141                  12   \n",
       "\n",
       "   source_system_tab  source_type  song_length  genre_ids  artist_name  \\\n",
       "0                  6            8     0.428309        371         4252   \n",
       "1                  6            8    -0.796309        371        34892   \n",
       "2                  0            7    -0.563420        371        20609   \n",
       "3                  3            3     0.331818        371        44425   \n",
       "4                  2            2     1.219789        371        42400   \n",
       "\n",
       "   composer  lyricist  language  city        bd  gender  registered_via  \\\n",
       "0      8389      2681         9     0 -0.650309       2               1   \n",
       "1     74276     26024         6     3  0.873194       1               2   \n",
       "2     27775      9110         9     0 -0.650309       2               1   \n",
       "3     83027     34734         2     0 -0.650309       2               0   \n",
       "4     81151     32836         2     0 -0.650309       2               2   \n",
       "\n",
       "       time  registration_init_time_int  expiration_date_int  \n",
       "0 -0.356394                    1.201362            -2.210220  \n",
       "1  0.553126                    0.119565             0.005168  \n",
       "2  1.359821                    1.162370            -0.304510  \n",
       "3 -1.189612                    0.283693             0.187798  \n",
       "4 -0.767353                   -0.430856            -1.582924  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tiny_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, dfX, dfy):\n",
    "        #'Initialization'\n",
    "        self.dfX = dfX\n",
    "        self.dfy = dfy\n",
    "#         self.numCol = numCol\n",
    "#         self.catCol = catCol\n",
    "    def __len__(self):\n",
    "        #'Denotes the total number of samples'\n",
    "        return len(self.dfX)\n",
    "#     def transform(self,dfX,numCol):\n",
    "#         X_num  = dfX[numCol].values\n",
    "#         X_num = StandardScaler().fit_transform(X_num)\n",
    "#         dfX[numCol] = X_num\n",
    "#         return dfX\n",
    "    def __getitem__(self, index):\n",
    "        #'Generates one sample of data'\n",
    "        # Load data and get label\n",
    "#         dfX_t = self.transform(self.dfX,self.numCol)\n",
    "        X = self.dfX.iloc[index]\n",
    "        X = torch.tensor(X)\n",
    "        y = self.dfy.target.iloc[index]\n",
    "        y = torch.tensor(y)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 4.8755e+06, 5.2240e+03, 1.4524e+05, 1.6000e+01, 6.0000e+00,\n",
       "        8.0000e+00, 2.0062e+05, 3.7100e+02, 3.4892e+04, 7.4276e+04, 2.6024e+04,\n",
       "        6.0000e+00, 3.0000e+00, 4.1000e+01, 1.0000e+00, 2.0000e+00, 4.9078e-01,\n",
       "        5.0000e+03, 6.4750e+03])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(train_X.iloc[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "MAX_EPOCH = 20\n",
    "SAVE_THRESHOLD = 0.6\n",
    "SAVE_RESULTS = True\n",
    "SAVE_LOGITS = False\n",
    "SEED = 229\n",
    "LOSS_HIST_ACCUM_FREQ = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# torch.manual_seed(SEED)\n",
    "# torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(20,40),\n",
    "    nn.BatchNorm1d(40),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40,20),\n",
    "    nn.BatchNorm1d(20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 [0]\n"
     ]
    }
   ],
   "source": [
    "device, gpu_ids = utils.get_available_devices()\n",
    "print(device,gpu_ids)\n",
    "#model = nn.DataParallel(model, gpu_ids)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "#criterion = torch.nn.BCEWithLogitsLoss()   # default\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=L2_PENALTY)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=4, min_lr=3e-5, verbose=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=4, \n",
    "                                                       min_lr=1e-4, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval();\n",
    "    test_loss = 0.0\n",
    "    true_ans_list = []\n",
    "    preds_cat = []\n",
    "    logits_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (features, targets) in enumerate(test_loader):\n",
    "            features = features.to(device=device) # move to device, e.g. GPU\n",
    "            targets = targets.to(device=device)\n",
    "            logits = model(features)\n",
    "            logits = torch.squeeze(logits,1)  \n",
    "            loss = F.binary_cross_entropy(F.sigmoid(logits), targets)\n",
    "            test_loss += loss.item()\n",
    "            true_ans_list.append(targets)\n",
    "            preds_cat.append(logits)\n",
    "            logits=logits.cpu().numpy()\n",
    "            logits_list.append(logits)\n",
    "\n",
    "        all_true_ans = torch.cat(true_ans_list)\n",
    "        all_preds = torch.cat(preds_cat)\n",
    "        all_preds = torch.ge(all_preds, 0.5)\n",
    "        all_true_ans=all_true_ans.cpu()\n",
    "        all_preds=all_preds.cpu()\n",
    "        f1_eval = f1_score(all_true_ans, all_preds, average='weighted')\n",
    "        # drop the last logits_list\n",
    "        logits_list = logits_list[:-1]\n",
    "        # print(\"list:\", logits_list)\n",
    "        all_logits = np.stack(logits_list)\n",
    "\n",
    "    return all_logits, all_true_ans, all_preds\n",
    "\n",
    "\n",
    "def validate(model, valid_loader):\n",
    "    model.eval();\n",
    "    test_loss = 0.0\n",
    "    true_ans_list = []\n",
    "    preds_cat = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        valid_iterator = valid_loader\n",
    "\n",
    "        for step, (features, targets) in enumerate(valid_iterator):\n",
    "            features = features.to(device=device) # move to device, e.g. GPU\n",
    "            targets = targets.to(device=device)\n",
    "            logits = model(features)\n",
    "            logits = torch.squeeze(logits,1)  \n",
    "            loss = F.binary_cross_entropy(F.sigmoid(logits), targets)\n",
    "            test_loss += loss.item()\n",
    "            true_ans_list.append(targets)\n",
    "            preds_cat.append(logits)\n",
    "\n",
    "        all_true_ans = torch.cat(true_ans_list)\n",
    "        all_preds = torch.cat(preds_cat)\n",
    "        all_preds = torch.ge(all_preds, 0.5)\n",
    "        all_true_ans=all_true_ans.cpu()\n",
    "        all_preds=all_preds.cpu()\n",
    "        # f1_eval = f1_score(all_true_ans, all_preds).item()\n",
    "        f1_eval = f1_score(all_true_ans, all_preds, average='weighted')\n",
    "\n",
    "    return test_loss / (step + 1), f1_eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda(x):\n",
    "    return x.cuda(non_blocking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN - Draft & Debugging on tiny dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_tiny = myDataset(train_tiny_X,train_tiny_y)\n",
    "val_dataset_tiny = myDataset(val_tiny_X, val_tiny_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tiny_loader = DataLoader(train_dataset_tiny, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_tiny_loader = DataLoader(val_dataset_tiny, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Epoch: 1\n",
      "mean train loss: 0.7017092737017032\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.680793\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train loss: 0.6998481951739098\n",
      "Evaluating...\n",
      "Validation loss: 0.703721\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 3\n",
      "mean train loss: 0.6987497721024045\n",
      "Evaluating...\n",
      "Validation loss: 0.710407\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 4\n",
      "mean train loss: 0.6994790964679293\n",
      "Evaluating...\n",
      "Validation loss: 0.689664\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 5\n",
      "mean train loss: 0.6980540488250236\n",
      "Evaluating...\n",
      "Validation loss: 0.683016\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 6\n",
      "mean train loss: 0.6981917588898279\n",
      "Evaluating...\n",
      "Validation loss: 0.714533\n",
      "Validation F1:  0.30974\n",
      "Epoch     5: reducing learning rate of group 0 to 5.0000e-02.\n",
      "starting Epoch: 7\n",
      "mean train loss: 0.6976540876445766\n",
      "Evaluating...\n",
      "Validation loss: 0.680625\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 8\n",
      "mean train loss: 0.6972023834266597\n",
      "Evaluating...\n",
      "Validation loss: 0.703615\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 9\n",
      "mean train loss: 0.697888454493376\n",
      "Evaluating...\n",
      "Validation loss: 0.704461\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 10\n",
      "mean train loss: 0.6974212497196935\n",
      "Evaluating...\n",
      "Validation loss: 0.692548\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 11\n",
      "mean train loss: 0.6970192864153559\n",
      "Evaluating...\n",
      "Validation loss: 0.685185\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 12\n",
      "mean train loss: 0.6979566037338542\n",
      "Evaluating...\n",
      "Validation loss: 0.705528\n",
      "Validation F1:  0.30974\n",
      "Epoch    11: reducing learning rate of group 0 to 2.5000e-02.\n",
      "starting Epoch: 13\n",
      "mean train loss: 0.6965921857885782\n",
      "Evaluating...\n",
      "Validation loss: 0.692891\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 14\n",
      "mean train loss: 0.6969863234774795\n",
      "Evaluating...\n",
      "Validation loss: 0.692533\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 15\n",
      "mean train loss: 0.6967244851468241\n",
      "Evaluating...\n",
      "Validation loss: 0.690017\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 16\n",
      "mean train loss: 0.6969576075315834\n",
      "Evaluating...\n",
      "Validation loss: 0.687266\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 17\n",
      "mean train loss: 0.6968196603717299\n",
      "Evaluating...\n",
      "Validation loss: 0.709871\n",
      "Validation F1:  0.30974\n",
      "Epoch    16: reducing learning rate of group 0 to 1.2500e-02.\n",
      "starting Epoch: 18\n",
      "mean train loss: 0.6969708548190189\n",
      "Evaluating...\n",
      "Validation loss: 0.696556\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 19\n",
      "mean train loss: 0.6962884051933046\n",
      "Evaluating...\n",
      "Validation loss: 0.695765\n",
      "Validation F1:  0.30974\n",
      "starting Epoch: 20\n",
      "mean train loss: 0.6963512123910863\n",
      "Evaluating...\n",
      "Validation loss: 0.692016\n",
      "Validation F1:  0.30974\n",
      "Best F1 is 0.30974 on epoch 20\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LOAD_MODEL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-78e9c025ce58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m# Load weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mLOAD_MODEL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'output/best_model3.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m#log.info('Loading weights from {}...'.format(model_path))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LOAD_MODEL' is not defined"
     ]
    }
   ],
   "source": [
    "train_loss_history = []\n",
    "train_epoch_losses = []\n",
    "valid_losses = []\n",
    "valid_f1s = []\n",
    "best_model_f1 = 0.0\n",
    "best_model = None\n",
    "best_model_ep = 0\n",
    "num_ = len(os.listdir('output/')) + 1\n",
    "\n",
    "for epoch in range(1, MAX_EPOCH + 1):\n",
    "    #log.info('Starting epoch {}...'.format(epoch))\n",
    "    print('starting Epoch:',epoch)\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    #train_tqdm = tqdm(train_tiny_loader)\n",
    "    train_loss_curr_epoch = []\n",
    "\n",
    "    for step, (features, targets) in enumerate(train_tiny_loader):\n",
    "        features = features.to(device=device) # move to device, e.g. GPU\n",
    "        #features = features.requires_grad_()\n",
    "        targets = targets.to(device=device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(features)\n",
    "        logits = torch.squeeze(logits,1)        \n",
    "        loss = F.binary_cross_entropy(torch.sigmoid(logits), targets)\n",
    "        loss.backward()\n",
    "\n",
    "#         nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if (step+1) % LOSS_HIST_ACCUM_FREQ == 0:\n",
    "            tr_loss_ = total_loss / step\n",
    "            #tr_loss_= loss.item()\n",
    "            train_loss_history.append(tr_loss_)\n",
    "            train_loss_curr_epoch.append(tr_loss_)\n",
    "\n",
    "    avg_epoch_loss = np.mean(train_loss_curr_epoch)\n",
    "    print('mean train loss:', avg_epoch_loss)\n",
    "    train_epoch_losses.append(avg_epoch_loss)\n",
    "\n",
    "    print('Evaluating...')\n",
    "    valid_loss, valid_f1 = validate(model, val_tiny_loader)\n",
    "    print('Validation loss:',(round(valid_loss, 6)))\n",
    "    print('Validation F1: ',(round(valid_f1, 5)))\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    valid_f1s.append(valid_f1)\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    if valid_f1 >= best_model_f1:\n",
    "        best_model = model\n",
    "        best_model_f1 = valid_f1\n",
    "        best_model_ep = epoch\n",
    "\n",
    "    if (epoch > 3) and (epoch % 4 == 0) and best_model_f1 > SAVE_THRESHOLD:\n",
    "        #log.info('Saving best model ({})...'.format(num_))\n",
    "        model_pt = 'output/best_model{}.pt'.format(num_)\n",
    "        torch.save(best_model, model_pt)\n",
    "\n",
    "    if (epoch > 3) and SAVE_RESULTS:\n",
    "        results_dict = dict()\n",
    "        results_dict['train_loss_history'] = train_loss_history\n",
    "        results_dict['valid_loss'] = valid_losses\n",
    "        results_dict['valid_f1'] = valid_f1s\n",
    "        results_path = 'output/results{}.json'.format(num_)\n",
    "        with open(results_path, 'w') as fp:\n",
    "            json.dump(results_dict, fp, indent=4)\n",
    "\n",
    "    if (epoch > 7) and (utils.check_early_stopping(valid_losses, patience=6, threshold=3e-3)):\n",
    "        #log.info('Early stopping...')\n",
    "        break\n",
    "\n",
    "print('Best F1 is',round(best_model_f1, 5), 'on epoch',best_model_ep)\n",
    "\n",
    "\n",
    "# Save model (remember to change model name)\n",
    "if best_model_f1 > SAVE_THRESHOLD:\n",
    "    #log.info('Saving best model...')\n",
    "    torch.save(best_model, 'output/best_model{}.pt'.format(num_))\n",
    "\n",
    "if SAVE_LOGITS:\n",
    "    #log.info('Saving test set info...')\n",
    "    test_logits, test_true_ans, test_preds = test(best_model, test_loader)\n",
    "    # test_logits = test_logits.cpu().numpy()\n",
    "    test_true_ans = test_true_ans.cpu().numpy()\n",
    "    test_preds = test_preds.cpu().numpy()\n",
    "    test_path = 'output/test_results{}.npz'.format(num_)\n",
    "    np.savez(test_path, test_logits=test_logits, test_true_ans=test_true_ans, test_preds=test_preds)\n",
    "\n",
    "# Load weights\n",
    "if LOAD_MODEL:\n",
    "    model_path = 'output/best_model3.pt'\n",
    "    #log.info('Loading weights from {}...'.format(model_path))\n",
    "\n",
    "    # model.load_state_dict(torch.load('output/saved/best_model1.pt'))\n",
    "    model = torch.load(model_path)\n",
    "    model.to(device)\n",
    "    # model.eval()\n",
    "    # valid_loss, valid_f1 = validate(model, test_loader, criterion, need_tqdm=False)\n",
    "\n",
    "if SAVE_PLOT:\n",
    "    xs = list(range(1, len(train_epoch_losses) + 1))\n",
    "    plt.title('Loss')\n",
    "    plt.plot(xs, train_epoch_losses, '-o', label = 'train')\n",
    "    plt.plot(xs, valid_losses, '-o', label = 'valid')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig('output/train_val_loss_dense{}.png'.format(num_))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.title('F1')\n",
    "    plt.plot(xs, valid_f1s, '-o')\n",
    "    plt.ylabel('Valid F1')\n",
    "    plt.xticks(xs);\n",
    "    plt.xlabel('epoch');\n",
    "    plt.savefig('output/valid_f1{}.png'.format(num_))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN - Full dataset w/o tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN - Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
